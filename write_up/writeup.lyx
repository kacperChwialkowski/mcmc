#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
% from the icml 2016 example tex file
\usepackage{times}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
%\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{icml2016} 
\usepackage{placeins}

%\usepackage[accepted]{icml2016}


\newcommand{\heiko}[1]{   {\bf \color{blue}{HS: #1}}  }
\newcommand{\kacper}[1]{   {\bf \color{red}{K: #1}}  }
\newcommand{\arthur}[1]{   {\bf \color{magenta}{AG: #1}}  }

%\newcommand{\heiko}[1]{}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
theorems-sec
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
twocolumn[ 
\backslash
icmltitle{A Kernel Test of Goodness of Fit}
\end_layout

\begin_layout Plain Layout

% It is OKAY to include author information, even for blind
\end_layout

\begin_layout Plain Layout

% submissions: the style file will automatically remove it for you
\end_layout

\begin_layout Plain Layout

% unless you've provided the [accepted] option to the icml2015
\end_layout

\begin_layout Plain Layout

% package.
\end_layout

\begin_layout Plain Layout


\backslash
icmlauthor{Kacper Chwialkowski$^*$}{kacper.chwialkowski@gmail.com}
\end_layout

\begin_layout Plain Layout


\backslash
icmlauthor{Heiko Strathmann$^*$}{heiko.strathmann@gmail.com}
\end_layout

\begin_layout Plain Layout


\backslash
icmlauthor{Arthur Gretton}{arthur.gretton@gmail.com}
\end_layout

\begin_layout Plain Layout


\backslash
icmladdress{Gatsby Unit, University College London, United Kingdom}
\end_layout

\begin_layout Plain Layout

% You may provide any keywords that you 
\end_layout

\begin_layout Plain Layout

% find helpful for describing your paper; these are used to populate
\end_layout

\begin_layout Plain Layout

% the "keywords" metadata in the PDF but will not be shown in the document
\end_layout

\begin_layout Plain Layout


\backslash
icmlkeywords{kernel methods, goodness-of-fit, Stein's method, statistical
 testing}
\end_layout

\begin_layout Plain Layout


\backslash
vskip 0.3in ]
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Abstract
We propose a nonparametric statistical test for goodness-of-fit: given a
 set of samples, the test determines how likely it is that these were generated
 from a target density function.
 The measure of goodness-of-fit is a divergence constructed via Stein's
 method using functions from a Reproducing Kernel Hilbert Space.
 Our test statistic is based on an empirical estimate of this divergence,
 taking the form of a V-statistic in terms of the log gradients of the target
 density and the kernel.
 We derive a statistical test, both for i.i.d.
 and non-i.i.d.
 samples, where we estimate the null distribution quantiles using a wild
 bootstrap procedure.
 We apply our test to quantifying convergence of approximate Markov Chain
 Monte Carlo methods, statistical model criticism, and evaluating quality
 of fit vs model complexity in nonparametric density estimation.1
\end_layout

\begin_layout Standard

\lang english
\begin_inset FormulaMacro
\newcommand{\ev}{\mathbb{E}}
{\mathbb{E}}
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Statistical tests of goodness-of-fit are a fundamental tool in statistical
 analysis, dating back to the test of Kolmogorov and Smirnov 
\begin_inset CommandInset citation
LatexCommand citep
key "Kolmogorov33,Smirnov48"

\end_inset

.
 Given a set of samples 
\begin_inset Formula $\{Z_{i}\}_{i=1}^{n}$
\end_inset

 with distribution 
\begin_inset Formula $Z_{i}\sim q$
\end_inset

, our interest is in whether 
\begin_inset Formula $q$
\end_inset

 matches some reference or target distribution 
\begin_inset Formula $p$
\end_inset


\lang english
, which we assume to be only known up to the normalisation constant.
 Recently, in the multivariate setting, 
\lang british

\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring"

\end_inset

 proposed an elegant measure of sample quality with respect to a target.
 This measure is a maximum discrepancy between empirical sample expectations
 and target expectations over a large class of test functions, constructed
 so as to have zero expectation over the target distribution by use of a
 Stein operator.
 This operator depends only on the derivative of the 
\begin_inset Formula $\log q$
\end_inset

: thus, the approach can be applied very generally, as it does not require
 closed-form integrals over the target distribution (or numerical approximations
 of such integrals).
 By contrast, many earlier discrepancy measures require integrals with respect
 to the target (see below for a review).
 This is problematic if the intention is to perform benchmarks for assessing
 Markov Chain Monte Carlo, since these integrals will certainly not be known
 to the practitioner.
\end_layout

\begin_layout Standard
A challenge in applying the approach of 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "gorham2015measuring"

\end_inset

 is the complexity of the function class used, which results from applying
 the Stein operator to the 
\begin_inset Formula $W^{2,\infty}$
\end_inset

 Sobolev space.
 Thus, their sample quality measure requires solving a linear program that
 arises from a complicated construction of graph Stein discrepancies and
 geometric spanners.
 Their metric furthermore requires access to nontrivial lower bounds that,
 despite being provided for log-concave densities, are a largely open problem
 otherwise, in particular for multivariate cases.
\end_layout

\begin_layout Standard
An important application of a goodness-of-fit measure is in statistical
 testing, where it is desired to determine whether the empirical discrepancy
 measure is large enough to reject the null hypothesis (that the sample
 arises from the target distribution).
 One approach is to establish the asymptotic behaviour of the test statistic,
 and to set a test threshold at a large quantile of the asymptotic distribution.
 The asymptotic behaviour of the 
\begin_inset Formula $W^{2,\infty}$
\end_inset

-Sobolev Stein discrepancies remains a challenging open problem, due to
 the complexity of the function class used.
 It is not clear how one would compute p-values for this statistic, or determine
 when the goodness of fit test would allow us to accept the null hypothesis
 (at the user-specified test level).
\end_layout

\begin_layout Standard
The key contribution of this work is to define a statistical test of goodness-of
-fit, based on a Stein discrepancy computed in a Reproducing Kernel Hilbert
 Space (RKHS).
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
%AG
\end_layout

\end_inset

 To construct our test statistic, we use a function class defined by applying
 the Stein operator to a chosen space of RKHS functions, as proposed by
 
\begin_inset CommandInset citation
LatexCommand citep
key "OatGirCho15"

\end_inset

.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citeauthor
key "OatGirCho15"

\end_inset

 addressed the problem variance reduction in Monte Carlo integration, using
 the Stein operator to avoid bias.
 
\end_layout

\end_inset

 Our measure of goodness of fit is the largest discrepancy over this space
 of functions between empirical sample expectations and target expectations
 (the latter being zero, due to the effect of the Stein operator).
 The approach is a natural extension to goodness-of-fit testing of the earlier
 two-sample tests 
\begin_inset CommandInset citation
LatexCommand citep
key "gretton2012kernel"

\end_inset

 and independence tests 
\begin_inset CommandInset citation
LatexCommand citep
key "gretton_kernel_2008"

\end_inset

 based on the maximum mean discrepancy, which is an integral probability
 metric.
 As with these earlier tests, our statistic is a simple V-statistic, and
 can be computed in closed form and in quadratic time; moreover, it is an
 unbiased estimate of the corresponding population discrepancy.
 As with all Stein-based discrepancies, only the gradient of the log-density
 of the target density is needed; we do not require integrals with respect
 to the target density -- including the normalisation constant.
 Given that our test statistic is a V-statistic, we may make use of the
 extensive literature on asymptotics of V-statistics to formulate a hypothesis
 test 
\begin_inset CommandInset citation
LatexCommand citep
key "serfling80,leucht_dependent_2013"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
%AG
\end_layout

\end_inset

 We are able to provide statistical tests for both uncorrelated and correlated
 samples, where the latter is essential if the test is to be used in assessing
 the quality of output of an MCMC procedure.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
%AG
\end_layout

\end_inset

 An identical test was obtained simultaneously in independent work by 
\begin_inset CommandInset citation
LatexCommand citet
key "LiuLeeJor16"

\end_inset

, for uncorrelated samples.
\end_layout

\begin_layout Standard
Several alternative approaches exist in the statistics literature to goodness-of
-fit testing.
 A first strategy is to partition the space, and to conduct the test on
 a histogram estimate of the distribution 
\begin_inset CommandInset citation
LatexCommand citep
key "Bar89,Beirlant2,Gyorfi,GyVa02"

\end_inset

.

\lang english
 Such space partitioning approaches can have attractive theoretical properties
 (e.g.
 distribution-free test thresholds) and work well in low dimensions, however
 they are much less powerful than alternatives once the dimensionality increases
 
\begin_inset CommandInset citation
LatexCommand cite
key "GreGyo10"

\end_inset

.

\lang british
 A second popular approach has been to use the smoothed 
\begin_inset Formula $L_{2}$
\end_inset

 distance between the empirical characteristic function of the sample, and
 the characteristic function of the target density.
 This dates back to the test of Gaussianity of 
\begin_inset CommandInset citation
LatexCommand citet
key "BaringhausHenze88"

\end_inset

, who used a squared exponential smoothing function (see Eq.
 2.1 in their paper).
 For this choice of smoothing function, their statistic is identical to
 the maximum mean discrepancy (MMD) with the squared exponential kernel,
 which can be shown using the Bochner representation of the kernel (compare
 with 
\begin_inset CommandInset citation
LatexCommand citealt
after "Corollary 4"
key "SriGreFukLanetal10"

\end_inset

).
 It is essential in this case that the target distribution be Gaussian,
 since the convolution with the kernel (or in the Fourier domain, the smoothing
 function) must be available in closed form.
 An 
\begin_inset Formula $L_{2}$
\end_inset

 distance between Parzen window estimates can also be used  
\begin_inset CommandInset citation
LatexCommand citep
key "BowFos93"

\end_inset

, giving the same expression again, although the optimal choice of bandwidth
 for consistent Parzen window estimates may not be a good choice for testing
 
\begin_inset CommandInset citation
LatexCommand citep
key "AndHalTit94"

\end_inset

.
 A different smoothing scheme in the frequency domain results in an energy
 distance statistic 
\begin_inset CommandInset citation
LatexCommand citep
before "this likewise being an MMD with a particular choice of kernel; see "
key "SejSriGreFuk13"

\end_inset

, which can be used in a test of normality 
\begin_inset CommandInset citation
LatexCommand citep
key "SzeRiz05"

\end_inset

.
 The key point is that the required integrals are again computable in closed
 form for the Gaussian, although the reasoning may be extended to certain
 other families of interest, e.g.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Rizzo09"

\end_inset

.
 The requirement of computing closed-form integrals with respect to the
 test distribution severely restricts this testing strategy.
 Finally, a problem related to goodness-of-fit testing is that of model
 criticism 
\begin_inset CommandInset citation
LatexCommand citep
key "lloyd2015statistical"

\end_inset

.
 In this setting, samples generated from a fitted model are compared via
 the maximum mean discrepancy with samples used to train the model, such
 that a small MMD indicates a good fit.
 There are two limitation to the method: first, it requires samples from
 the model (which might not be easy if this requires a complex MCMC sampler);
 second, the choice of number of samples from the model is not obvious,
 since too few samples cause a loss in test power, and too many are computationa
lly wasteful.
 Neither issue arises in our test, since we do not require model samples.
\end_layout

\begin_layout Standard
In our experiments, a particular focus is on applying our goodness-of-fit
 test to certify the output of approximate Markov Chain Monte Carlo (MCMC)
 samplers 
\begin_inset CommandInset citation
LatexCommand citep
key "Korattikara2014,Welling2011,Bardenet2014"

\end_inset

.
 These methods use modifications to Markov transition kernels that improve
 mixing speed at the cost of worsening the asymptotic bias.
 The bias-variance trade-off can usually be tuned with parameters of the
 sampling algorithms.
 It is therefore important to test whether for a particular parameter setting
 and run-time, the samples are of the desired quality.
 This question cannot be answered with classical MCMC convergence statistics,
 such as the widely used potential scale reduction factor (R-factor) 
\begin_inset CommandInset citation
LatexCommand citep
key "gelman1992inference"

\end_inset

 or the effective sample size, since these assume that the Markov chain
 reaches its equilibrium distribution.
 By contrast, our test exactly quantifies the asymptotic bias of approximate
 MCMC.
 
\end_layout

\begin_layout Standard
Code can be found at 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/karlnapf/kernel_goodness_of_fit"
target "https://github.com/karlnapf/kernel_goodness_of_fit"

\end_inset

.
\end_layout

\begin_layout Paragraph
Paper outline
\end_layout

\begin_layout Standard
We begin our presentation in the section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:A-Kernel-Goodness-of-fit"

\end_inset

 with a high-level construction of the RKHS-based Stein discrepancy and
 associated statistical test.
 In Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Details"

\end_inset

, we provide additional details and prove the main results.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:experiment"

\end_inset

 contains experimental illustrations on synthetic examples, statistical
 model criticism, bias-variance trade-offs in approximate MCMC, and convergence
 in non-parametric density estimation.
\end_layout

\begin_layout Section

\lang english
Test Definition: Statistic and Threshold
\begin_inset CommandInset label
LatexCommand label
name "sec:A-Kernel-Goodness-of-fit"

\end_inset


\end_layout

\begin_layout Standard

\lang english
We begin with a high-level construction of our divergence discrepancy and
 the statistical test.
 While this section aims to communicate the main ideas, we provide details
 and proofs in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Details"

\end_inset

.
\end_layout

\begin_layout Subsection

\lang english
Stein Operator in RKHS
\end_layout

\begin_layout Standard

\lang english
Our goal is to write the maximum discrepancy between target distribution
 
\begin_inset Formula $p$
\end_inset

 and observed sample distribution 
\begin_inset Formula $q$
\end_inset

 in a RKHS.
 Denote by 
\begin_inset Formula ${\cal F}$
\end_inset

 the RKHS of real-valued functions on 
\begin_inset Formula $\mathbb{R}^{d}$
\end_inset

 with reproducing kernel 
\begin_inset Formula $k$
\end_inset

, and by 
\begin_inset Formula ${\cal F}^{d}$
\end_inset

 the product RKHS consisting of elements 
\begin_inset Formula $f:=(f_{1},\dots,f_{d})$
\end_inset

 with 
\begin_inset Formula $f_{i}\in{\cal F}$
\end_inset

, and with a standard inner product 
\begin_inset Formula $\left\langle f,g\right\rangle _{\mathcal{F}^{d}}=\sum_{i=1}^{d}\left\langle f_{i},g_{i}\right\rangle _{\mathcal{F}}$
\end_inset

.
 We further assume that all measures considered in this paper supported
 on an open set, equal to zero on the border and strictly positive (so logarithm
s are well defined) 
\begin_inset Foot
status open

\begin_layout Plain Layout

\lang english
An example of such a space is the real line
\end_layout

\end_inset

.
 Similarly to 
\begin_inset CommandInset citation
LatexCommand citet
key "stein1972,gorham2015measuring,OatGirCho15"

\end_inset

, we begin by defining a Stein operator 
\begin_inset Formula $T$
\end_inset

 acting on 
\begin_inset Formula $f\in\mathcal{F}^{d}$
\end_inset

 
\begin_inset Formula 
\[
T_{p}f:=\sum_{i=1}^{d}\left(\frac{\partial\log p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}\right).
\]

\end_inset

Suppose a random variable 
\begin_inset Formula $Z$
\end_inset

 is distributed according to a measure
\begin_inset Foot
status open

\begin_layout Plain Layout
Throughout the article, all occurrences of 
\begin_inset Formula $Z$
\end_inset

, e.g.
 
\begin_inset Formula $Z',Z_{i},Z_{\heartsuit}$
\end_inset

, are understood to be distributed according to 
\begin_inset Formula $q$
\end_inset

.
\end_layout

\end_inset

 
\begin_inset Formula $q$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

 is distributed according to the target measure 
\begin_inset Formula $p$
\end_inset

.
 As we will see, the operator can be expressed by defining a function that
 depends on gradients of the log-density and the kernel, 
\begin_inset Formula 
\begin{equation}
\xi_{p}(x,\cdot):=\left[\nabla\log p(x)k(x,\cdot)+\nabla k(x,\cdot)\right],\label{eq:xi}
\end{equation}

\end_inset

whose expected inner product with 
\begin_inset Formula $f$
\end_inset

 gives exactly the expected value of the Stein operator 
\begin_inset Formula 
\[
\ev_{q}T_{p}f(Z)=\langle f,\ev_{q}\xi_{p}(Z)\rangle_{{\cal F}^{d}}=\sum_{i=1}^{d}\langle f_{i},\ev_{q}\xi_{p,i}(Z)\rangle_{{\cal F}},
\]

\end_inset

For 
\begin_inset Formula $X$
\end_inset

 from the target measure, we have 
\begin_inset Formula $\ev_{p}(T_{p}f)(X)=0$
\end_inset

, which can be seen using integration by parts, c.f.
 Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:easy"

\end_inset

 in the supplement.
 We can now define a Stein discrepancy and express it in the RKHS,
\begin_inset Formula 
\begin{align*}
S_{p}(Z) & :=\sup_{\Vert f\Vert<1}\ev_{q}(T_{p}f)(Z)-\ev_{p}(T_{p}f)(X)\\
 & =\sup_{\Vert f\Vert<1}\ev_{q}(T_{p}f)(Z)\\
 & =\sup_{\Vert f\Vert<1}\langle f,\ev_{q}\xi_{p}(Z)\rangle_{{\cal F}^{d}}\\
 & =\|\ev_{q}\xi_{p}(Z)\|_{{\cal F}^{d}},
\end{align*}

\end_inset

This makes it clear why 
\begin_inset Formula $\ev_{p}(T_{p}f)(X)=0$
\end_inset

 is a desirable property: we can compute 
\begin_inset Formula $S_{p}(Z)$
\end_inset

 by computing 
\begin_inset Formula $\|\ev_{q}\xi_{p}(Z)\|$
\end_inset

, without the need to access 
\begin_inset Formula $X$
\end_inset

 in the form of samples from 
\begin_inset Formula $p$
\end_inset

.
 To state our first result we define 
\begin_inset Formula 
\begin{align*}
h_{p}(x,y) & :=\nabla\log p(x)^{\top}\nabla\log p(y)k(x,y)\\
 & \quad+\nabla\log p(y)^{\top}\nabla_{x}k(x,y)\\
 & \quad+\nabla\log p(x){}^{\top}\nabla_{y}k(x,y)\\
 & \quad+\langle\nabla_{x}k(x,\cdot),\nabla_{y}k(\cdot,y)\rangle_{{\cal F}^{d}},
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\lang english
where the last term can be written as a sum 
\begin_inset Formula $\sum_{\{i=1\}}^{d}\frac{\partial k(x,y)}{\partial x_{i}\partial y_{i}}$
\end_inset

.
 
\lang british
The following theorem gives a simple closed form expression for 
\begin_inset Formula $\|\ev_{q}\xi_{p}(Z)\|_{{\cal F}^{d}}$
\end_inset

.
\end_layout

\begin_layout Theorem

\lang english
\begin_inset CommandInset label
LatexCommand label
name "th:closed_form_discrepancy"

\end_inset

 If 
\begin_inset Formula $Eh_{p}(Z,Z)<\infty$
\end_inset

, then 
\begin_inset Formula $S_{p}^{2}(Z)=\|\ev_{q}\xi_{p}(Z)\|_{{\cal F}^{d}}^{2}=\ev_{q}h_{p}(Z,Z')$
\end_inset

.

\lang british
 
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
The second main result, states that the discrepancy 
\begin_inset Formula $S_{p}(Z)$
\end_inset

 can be used to distinguish two distributions.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem

\lang english
\begin_inset CommandInset label
LatexCommand label
name "theorem_discrepancy_is_metric"

\end_inset

 Let 
\begin_inset Formula $q,p$
\end_inset

 be probability measures and 
\begin_inset Formula $Z\sim q$
\end_inset

.
 If the kernel 
\begin_inset Formula $k$
\end_inset

 is cc-universal 
\begin_inset CommandInset citation
LatexCommand citep
after "Definition 4.1"
key "carmeli2010vector"

\end_inset

, 
\begin_inset Formula $\ev_{q}h_{q}(Z,Z)<\infty$
\end_inset

 and 
\begin_inset Formula $\ev_{q}\|\nabla\left(\log\frac{p(Z)}{q(Z)}\right)\|^{2}<\infty$
\end_inset

 then 
\begin_inset Formula $S_{p}(Z)=0$
\end_inset

 if and only if 
\begin_inset Formula $p=q$
\end_inset

.
\end_layout

\begin_layout Standard
Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:details_kernel_stein"

\end_inset

 contains proofs.
 We now proceed with constructing an estimator for 
\begin_inset Formula $S(Z)^{2}$
\end_inset

, and outline its asymptotic properties.
\end_layout

\begin_layout Subsection
Wild Bootstrap Testing
\end_layout

\begin_layout Standard
It is straightforward to estimate the squared Stein discrepancy 
\begin_inset Formula $S(Z)^{2}$
\end_inset

 from samples 
\begin_inset Formula $\{Z_{i}\}_{i=1}^{n}$
\end_inset

: a quadratic time estimator is a V-Statistic, and takes the form
\begin_inset Formula 
\[
V_{n}=\frac{1}{n^{2}}\sum_{i,j=1}^{n}h_p(Z_{i},Z_{j}).
\]

\end_inset

 The asymptotic null distribution of the normalised V-Statistic 
\begin_inset Formula $nV_{n}$
\end_inset

, however, has no computable closed form.
 Furthermore, care has to be taken when the 
\begin_inset Formula $Z_{i}$
\end_inset

 exhibit correlation structure, as the null distribution significantly changes,
 impacting test significance.
 The wild bootstrap technique 
\begin_inset CommandInset citation
LatexCommand citep
key "Shao2010,leucht_dependent_2013,FroLauLerRey12"

\end_inset

 addresses both problems.
 First, it allows to simulate from the null distribution to compute test
 thresholds.
 Second, it accounts for correlation structure in the 
\begin_inset Formula $Z_{i}$
\end_inset

 by mimicking it with an 
\lang english
auxiliary
\lang british
 random process: a
\lang english
 Markov chain taking values in 
\begin_inset Formula $\{-1,1\}$
\end_inset

, starting from 
\begin_inset Formula $W_{1,n}=1$
\end_inset

,
\lang british

\begin_inset Formula 
\[
W_{t,n}=\mathbf{1}(U_{t}>a_{n})W_{t-1,n}-\mathbf{1}(U_{t}<a_{n})W_{t-1,n},
\]

\end_inset


\lang english
where the 
\begin_inset Formula $U_{t}$
\end_inset

 are uniform i.i.d.
 random variables and 
\begin_inset Formula $a_{n}$
\end_inset

 is the probability of 
\begin_inset Formula $W_{t,n}$
\end_inset

 changing sign (for i.i.d.
 data we may set 
\begin_inset Formula $a_{n}=0.5$
\end_inset

).
 This leads to a bootstrapped V-statistic 
\end_layout

\begin_layout Standard

\emph on
\lang english
\begin_inset Formula 
\[
B_{n}=\frac{1}{n^{2}}\sum_{i,j=1}^{n}W_{i,n}W_{j,n}h_p(Z_{i,}Z_{j}).
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:wild_bootstrap_works"

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
 establishes that, under the null hypothesis, 
\begin_inset Formula $nB_{n}$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
 is a good approximation
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
of 
\begin_inset Formula $nV_{n}$
\end_inset

, so it is possible to approximate quantiles of the null distribution by
 sampling from it.
 Under the alternative, however, 
\begin_inset Formula $V_{n}$
\end_inset

 dominates 
\begin_inset Formula $B_{n}$
\end_inset

 -- resulting in almost sure rejection of the null hypothesis.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
We propose the following test
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
 procedure for testing the null hypothesis that the 
\begin_inset Formula $Z_{i}$
\end_inset

 are distributed according to the target distribution 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Itemize
Calculate 
\lang english
the test statistic 
\begin_inset Formula $V_{n}$
\end_inset

.
\end_layout

\begin_layout Itemize

\lang english
Obtain wild bootstrap samples
\lang british
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $\{B_{n}\}_{i=1}^{D}$
\end_inset

 and estimate the 
\begin_inset Formula $1-\alpha$
\end_inset

 empirical quantile of these samples.
 
\end_layout

\begin_layout Itemize

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
If 
\begin_inset Formula $V_{n}$
\end_inset

 exceeds the quantile, reject.
\end_layout

\begin_layout Section

\lang english
Proofs of the Main Results
\begin_inset CommandInset label
LatexCommand label
name "sec:Details"

\end_inset


\end_layout

\begin_layout Standard

\lang english
We now prove the claims made in the previous Section.
\end_layout

\begin_layout Subsection

\lang english
Stein Operator in RKHS
\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset label
LatexCommand label
name "sec:details_kernel_stein"

\end_inset


\end_layout

\begin_layout Standard

\lang english
Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:easy"

\end_inset

 (in the Appendix) shows that the expected value of the Stein operator is
 zero on the target measure.
\end_layout

\begin_layout Proof

\lang english
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\lang english
Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:closed_form_discrepancy"

\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Proof

\lang english
\begin_inset Formula $\xi_p(x,\cdot)$
\end_inset

 is an element of the reproducing kernel Hilbert space 
\begin_inset Formula $\mathcal{F}^{d}$
\end_inset

 -- by 
\begin_inset CommandInset citation
LatexCommand citet
after "Lemma 4.34"
key "SteChr08"

\end_inset

 
\begin_inset Formula $\nabla k(x,\cdot)\in\mathcal{F}$
\end_inset

, and 
\begin_inset Formula $\frac{\partial\log p(x)}{\partial x_{i}}$
\end_inset

 is just a scalar.
 
\lang british
We first show that 
\begin_inset Formula $h_p(x,y)=\langle\xi_p(x,\cdot),\xi_p(y,\cdot)\rangle.$
\end_inset

 Using notation
\begin_inset Formula 
\begin{align*}
\nabla_{x}k(x,\cdot) & =\left(\frac{\partial k(x,\cdot)}{\partial x_{1}},\cdots,\frac{\partial k(x,\cdot)}{\partial x_{d}}\right)\\
\nabla_{y}k(\cdot,y) & =\left(\frac{\partial k(\cdot,y)}{\partial y_{1}},\cdots,\frac{\partial k(\cdot,y)}{\partial y_{d}}\right),
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
we calculate 
\begin_inset Formula 
\begin{align*}
\langle\xi_{p}(x,\cdot),\xi_{p}(y,\cdot)\rangle & =\nabla\log p(x)^{\top}\nabla\log p(x)k(x,y)\\
 & \quad+\nabla\log p(x)\nabla_{x}k(x,y)\\
 & \quad+\nabla\log p(x){}^{\top}\nabla_{y}k(x,y)\\
 & \quad+\langle\nabla_{x}k(x,\cdot),\nabla_{y}k(\cdot,y)\rangle_{\mathcal{F}^{d}}.
\end{align*}

\end_inset


\lang english
Next we show that 
\begin_inset Formula $\xi_p(x,\cdot)$
\end_inset

 is Bochner integrable (see 
\begin_inset CommandInset citation
LatexCommand cite
after "Definition A.5.20"
key "SteChr08"

\end_inset

), which allows us to change order of the integration 
\begin_inset Formula 
\[
\ev_{q}\|\xi_{p}(Z)\|_{\mathcal{F}^{d}}\leq\ev_{q}\|\xi_{p}(Z)\|_{\mathcal{F}^{d}}^{2}=\ev_{q}h_{p}(Z,Z)<\infty.
\]

\end_inset


\end_layout

\begin_layout Proof
We 
\lang english
relate expected value of the Stein operator to the inner product of 
\begin_inset Formula $f$
\end_inset

 and the expected value of 
\begin_inset Formula $\xi_q(Z)$
\end_inset

, 
\begin_inset Formula 
\begin{align}
\ev_{q}T_{p}f(Z)=\langle f,\ev_{q}\xi_{p}(Z)\rangle_{\mathcal{F}^{d}} & =\sum_{i=1}^{d}\langle f_{i},\ev_{q}\xi_{p,i}(Z)\rangle_{\mathcal{F}}.\label{eq:expectedVauleT}
\end{align}

\end_inset


\end_layout

\begin_layout Proof

\lang english
We check the claim for all dimensions 
\begin_inset Formula 
\begin{align*}
 & \left\langle f_{i},\ev_{q}\xi_{i,p}(Z)\right\rangle _{\mathcal{F}}\\
 & =\left\langle f_{i},\ev_{q}\left[\frac{\partial\log p(Z)}{\partial x_{i}}k(Z,\cdot)+\frac{\partial k(Z,\cdot)}{\partial x_{i}}\right]\right\rangle _{\mathcal{F}}\\
 & =\ev_{q}\left\langle f_{i},\frac{\partial\log p(Z)}{\partial x_{i}}k(Z,\cdot)+\frac{\partial k(Z,\cdot)}{\partial x_{i}}\right\rangle _{\mathcal{F}}\\
 & =\ev_{q}\left[\frac{\partial\log p(Z)}{\partial x_{i}}f_{i}(Z)+\frac{\partial f_{i}(Z,\cdot)}{\partial x_{i}}\right].
\end{align*}

\end_inset


\end_layout

\begin_layout Proof

\lang english
The second equality follows from the fact that a linear operator 
\begin_inset Formula $\langle f_{i},\cdot\rangle_{\mathcal{F}}$
\end_inset

 can be interchanged with the Bochner integral, and the fact that 
\begin_inset Formula $\xi_p$
\end_inset

 is Bochner integrable.
 Using definition of 
\begin_inset Formula $S(Z)$
\end_inset

, Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:easy"

\end_inset

 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
and Equation 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expectedVauleT"

\end_inset

 we have 
\begin_inset Formula 
\begin{align*}
S_{p}(Z) & :=\sup_{\Vert f\Vert<1}\ev_{q}(T_{p}f)(Z)-\ev_{p}(T_{p}f)(X)\\
 & =\sup_{\Vert f\Vert<1}\ev_{q}(T_{p}f)(Z)\\
 & =\sup_{\Vert f\Vert<1}\langle f,\ev_{q}\xi_{p}(Z)\rangle_{{\cal F}^{d}}\\
 & =\|\ev_{q}\xi_{p}(Z)\|_{\mathcal{F}^{d}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
We 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
now calculate closed form formula for 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $S_{p}^{2}(Z)$
\end_inset


\end_layout

\begin_layout Proof

\lang english
\begin_inset Formula 
\begin{align*}
S_{p}^{2}(Z) & =\langle\ev_{q}\xi_{p}(Z),\ev_{q}\xi_{p}(Z)\rangle_{\mathcal{F}^{d}}=\ev_{q}\langle\xi_{p}(Z),\ev_{q}\xi_{p}(Z)\rangle_{\mathcal{F}^{d}}\\
 & =\ev_{q}\langle\xi_{p}(Z),\xi_{p}(Z')\rangle_{\mathcal{F}^{d}}=\ev_{q}h_{p}(Z,Z'),
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $Z'$
\end_inset

 is an independent copy of 
\begin_inset Formula $Z$
\end_inset

.
 Next, we prove that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
the discrepancy 
\begin_inset Formula $S$
\end_inset

 discriminates different probability measures.
 
\end_layout

\begin_layout Proof

\lang english
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\lang english
Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem_discrepancy_is_metric"

\end_inset


\end_layout

\end_inset

 If 
\begin_inset Formula $p=q$
\end_inset

 then 
\begin_inset Formula $S_{p}(Z)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 by Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:easy"

\end_inset

.
 Suppose 
\begin_inset Formula $p\neq q$
\end_inset

, but 
\begin_inset Formula $S_{p}(Z)=0$
\end_inset

.
 If 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $S_{p}(Z)=0$
\end_inset

 then, 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
by Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:closed_form_discrepancy"

\end_inset

,
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\ev_{q}\xi_{p}(Z)=0.$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 In the following we substitute 
\begin_inset Formula $\log p(Z)=\log q(Y)+[\log p(Z)-\log q(Y)]$
\end_inset

, 
\begin_inset Formula 
\begin{align*}
 & \ev_{q}\xi_{p}(Z)\\
 & =\ev_{q}\left(\nabla\log p(Z)k(Z,\cdot)+\nabla k(Z,\cdot)\right)\\
 & =\ev_{q}\xi_{q}(Z)+\ev_{q}\left(\nabla[\log p(Z)-\log q(Y)]k(Z,\cdot)\right)\\
 & =\ev_{q}\left(\nabla[\log p(Z)-\log q(Y)]k(Z,\cdot)\right)
\end{align*}

\end_inset

We have used Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:closed_form_discrepancy"

\end_inset

 and Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:easy"

\end_inset

 to see that 
\begin_inset Formula $\ev_{q}\xi_{q}(Z)=0$
\end_inset

, since 
\begin_inset Formula $\|\ev_{q}\xi_{q}(Z)\|^{2}=S_{q}(Z)=0$
\end_inset

.
 
\end_layout

\begin_layout Proof

\lang english
We 
\lang british
recognise
\lang english
 that the expected value of 
\begin_inset Formula $\nabla(\log p(Z)-\log q(Z))k(Z,\cdot)$
\end_inset

 is the mean embedding of a function 
\begin_inset Formula $g(y)=\nabla\left(\log\frac{p(y)}{q(y)}\right)$
\end_inset

 with respect to the measure 
\begin_inset Formula $q$
\end_inset

.
 By the assumptions function 
\begin_inset Formula $g$
\end_inset

 is square integrable, therefore, since the kernel 
\begin_inset Formula $k$
\end_inset

 is cc-universal, by 
\begin_inset CommandInset citation
LatexCommand citet
after " Theorem 4.4 c"
key "carmeli2010vector"

\end_inset

 its embedding is zero if and only if 
\begin_inset Formula $g=0$
\end_inset

.
 This implies that 
\begin_inset Formula 
\[
\nabla\log\frac{p(y)}{q(y)}=(0,\cdots,0).
\]

\end_inset

A constant vector field of derivatives can only be generated by a constant
 function, so 
\begin_inset Formula $\log\frac{p(y)}{q(y)}=C$
\end_inset

, for some 
\begin_inset Formula $C$
\end_inset

, which implies that 
\begin_inset Formula $p(y)=e^{C}q(y)$
\end_inset

.
 Since 
\begin_inset Formula $p$
\end_inset

 and 
\begin_inset Formula $q$
\end_inset

 both integrate to one, 
\begin_inset Formula $C=0$
\end_inset

 and so 
\begin_inset Formula $p=q$
\end_inset

 -- a contradiction.
\end_layout

\begin_layout Subsection
Wild Bootstrap Testing
\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset label
LatexCommand label
name "sub:details_testing"

\end_inset


\end_layout

\begin_layout Standard

\lang english
The two concepts required to derive the distribution of the test statistic
 are: 
\begin_inset Formula $\tau$
\end_inset

-mixing 
\begin_inset CommandInset citation
LatexCommand citep
key "dedecker2007weak,leucht_dependent_2013"

\end_inset

, and V-statistics 
\begin_inset CommandInset citation
LatexCommand citet
key "serfling80"

\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula $\tau$
\end_inset

-mixing is a notion of dependence within the observations, weak enough for
 most practical applications.
 Trivially, i.i.d.
 observations are 
\begin_inset Formula $\tau$
\end_inset

-mixing.
 As for Markov chains, whose convergence we study in the experiments, the
 property of geometric ergodicity implies 
\begin_inset Formula $\tau$
\end_inset

-mixing (given that the stationary distribution has a finite moment of some
 order: see 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:MCMC-convergence-testing"

\end_inset

 for more discussion.
 For further details on 
\begin_inset Formula $\tau$
\end_inset

-mixing, see 
\begin_inset CommandInset citation
LatexCommand citet
key "dedecker2005new,dedecker2007weak"

\end_inset

.
 For this work we will assume a technical condition 
\begin_inset Formula $\sum_{t=1}^{\infty}t^{2}\sqrt{\tau(t)}\leq\infty$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout

\lang english
To formally introduce 
\begin_inset Formula $\tau$
\end_inset

-mixing, let 
\begin_inset Formula $\{Z_{t},\mathcal{G}_{t}\}_{t\in\mathbb{N}}$
\end_inset

 be a stationary sequence of integrable random variables with respect to
 a natural filtration 
\begin_inset Formula $\mathcal{G}_{t}$
\end_inset

.
 The sequence is called 
\begin_inset Formula $\tau$
\end_inset

-dependent if 
\begin_inset Formula $\tau(r)$
\end_inset

 converges to zero with 
\begin_inset Formula $r$
\end_inset

 going to infinity, where 
\begin_inset Formula $\tau$
\end_inset

 is defined as follows 
\begin_inset Formula 
\begin{align*}
\tau(r) & :=\sup_{l\in\mathbb{N}}\frac{1}{l}\sup_{r\leq i_{1}...\leq i_{l}}L(Z_{i_{1}},...,Z_{i_{l}})\quad\text{with}\\
L(Z) & :=\ev\left(\sup_{g\in\Lambda}\left|\int g(t)(dP_{Z|\mathcal{\mathcal{G}}_{0}}-dP)\right|\right),
\end{align*}

\end_inset

where 
\begin_inset Formula $\Lambda$
\end_inset

 is the set of all one-Lipschitz continuous real-valued functions on the
 domain of 
\begin_inset Formula $Z$
\end_inset

.
 
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard

\lang english
A direct application of Theorem 2.1 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

 characterizes the limiting behavior of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $nV_{n}$
\end_inset

 for 
\begin_inset Formula $\tau$
\end_inset

-mixing processes,
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\end_layout

\begin_layout Proposition

\lang english
\begin_inset CommandInset label
LatexCommand label
name "thm: null_dist"

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
If 
\begin_inset Formula $h$
\end_inset

 is Lipschitz continuous and 
\begin_inset Formula $\ev_{q}h_p(Z,Z)<\infty$
\end_inset

 then, under the null hypothesis 
\begin_inset Formula $nV_{n},$
\end_inset

 converges weakly to some distribution.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
The proof, which is a simple verification of the assumptions, can be found
 in the Appendix.
 Although a formula for a limit distribution of 
\family default
\series bold
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $V_{n}$
\end_inset


\family roman
\series medium
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 can be derived explicitly (
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
Theorem 2.1
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

), we do not provide it here.
 To our knowledge there are no methods of obtaining quantiles of a limit
 of 
\family default
\series bold
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $V_{n}$
\end_inset


\family roman
\series medium
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 in closed form.
 The common solution is to estimate quantiles by a resampling method, as
 described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:A-Kernel-Goodness-of-fit"

\end_inset

.
 The validity of this resampling method is guaranteed by the following propositi
on (which follows from Theorem 2.1 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

 and modification of the Lemma 5 
\begin_inset CommandInset citation
LatexCommand citet
key "chwialkowski2014wild"

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 ) , proved in the supplement.
\end_layout

\begin_layout Proposition

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
\begin_inset CommandInset label
LatexCommand label
name "thm:wild_bootstrap_works"

\end_inset

Let 
\begin_inset Formula $f(Z_{1,n},\cdots,Z_{t,n})=\sup_{x}|P(nB_{n}>x|Z_{1,n},\cdots,Z_{t,n})-P(nV_{n}>x)|$
\end_inset

 be a difference between quantiles.
 If 
\begin_inset Formula $h$
\end_inset

 is Lipschitz continuous and 
\begin_inset Formula $\ev_{q}h_p(Z,Z)^{2}<\infty$
\end_inset

 then, under the null hypothesis, 
\begin_inset Formula $f(X_{1,n},\cdots,X_{t,n})$
\end_inset

 converges to zero in probability; under the alternative hypothesis, 
\begin_inset Formula $B_{n}$
\end_inset

 converges to zero, while 
\begin_inset Formula $V_{n}$
\end_inset

 converges to a positive constant.
\end_layout

\begin_layout Standard
As a consequence, if the null hypothesis is true, we can approximate any
 quantile; while under the alternative hypothesis, all quantiles of 
\begin_inset Formula $B_{n}$
\end_inset

 collapse to zero while 
\begin_inset Formula $P(V_{n}>0)\to1$
\end_inset

.
 We discuss specific case of testing MCMC convergence in the Appendix.
\end_layout

\begin_layout Section

\lang english
Experiments
\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset label
LatexCommand label
name "sec:experiment"

\end_inset


\end_layout

\begin_layout Standard

\lang english
We provide a number of experimental applications for our test.
 We begin with a simple check to establish correct test calibration on non-i.i.d.
 data, followed by a demonstration of statistical model criticism for Gaussian
 Process (GP) regression.
 We then apply the proposed test to quantify bias-variance trade-offs in
 MCMC, and demonstrate how to use the test to verify whether MCMC samples
 are drawn from the desired stationary distribution.
 In the final experiment, we move away from the MCMC setting, and
\lang british
 use the test to evaluate the convergence of a nonparametric density estimator.
 Code can be found at 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/karlnapf/kernel_goodness_of_fit"
target "https://github.com/karlnapf/kernel_goodness_of_fit"

\end_inset

.
\end_layout

\begin_layout Subsubsection*

\lang english
Student's t vs Normal
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\lang english
\begin_inset Graphics
	filename img/sgld_student_bad.pdf
	lyxscale 90

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Large autocovariance, unsuitable bootstrap.
 The parameter 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $a_{n}$
\end_inset

 is too large and the bootstrapped V-statistics 
\begin_inset Formula $B_{n}$
\end_inset

 are, on average, too low.
 Therefore it is very likely that 
\begin_inset Formula $V_{n}>B_{n}$
\end_inset

 and the test is too conservative.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british

\begin_inset CommandInset label
LatexCommand label
name "fig:student_bad"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
In our first task, we modify experiment 4.1 from 
\begin_inset CommandInset citation
LatexCommand citealt
key "gorham2015measuring"

\end_inset

.
 The null hypothesis is that the observed samples come from a standard normal
 distribution.
 We study the power of the test against samples from a Student's t distribution.
 We expect to observe low p-values when testing against a Student's t distributi
on with few degrees of freedom.
 We considered 1, 5, 10 or 
\begin_inset Formula $\infty$
\end_inset

 degrees of freedom, where 
\begin_inset Formula $\infty$
\end_inset

 is equivalent to sampling from a standard normal distribution.
 For a fixed number of degrees of freedom we drew 1400 samples and calculated
 the p-value.
 This procedure was repeated one hundred times, and the bar plots of p-values
 are shown in Figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:student_bad"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:studentst"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:thinning"

\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\lang english
\begin_inset Graphics
	filename img/sgld_student.pdf

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Large autocovariance, suitable bootstrap.
 The parameter 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $a_{n}$
\end_inset

is chosen suitably, but due to a large autocorrelation withing the samples,
 the power of the test is small (effective sample size is small).
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset CommandInset label
LatexCommand label
name "fig:studentst"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The twist on 
\lang english
the original experiment 4.1 by 
\begin_inset CommandInset citation
LatexCommand citealt
key "gorham2015measuring"

\end_inset

 is that in our case, the draws from the Student's t distribution were given
 temporal correlation.
 The samples were generated using a MetropolisHastings algorithm, with
 a Gaussian random walk (variance equal to 0.5).
 We emphasize the need for an appropriate choice of the wild bootstrap process
 parameter, 
\begin_inset Formula $a_{n}$
\end_inset

, which indicates the probability of a sign flip.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:student_bad"

\end_inset

 we plot p-values for 
\begin_inset Formula $a_{n}$
\end_inset

 being set to 
\begin_inset Formula $0.5$
\end_inset

.
 Such a high value of 
\begin_inset Formula $a_{n}$
\end_inset

 is 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
suitable for iid observations, but results in p-values that are too conservative
 for temporally correlated observations.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:studentst"

\end_inset

, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $a_{n}=0.02$
\end_inset

, which gives a well calibrated distribution of the p-values under the null
 hypothesis (see box plot for an infinite number degrees of freedom), however
 the power of the test is reduced.
 Indeed, p-values for five degrees of freedom are already large.
 The solution that we recommend is a mixture of thinning and adjusting 
\begin_inset Formula $a_{n},$
\end_inset

 as presented in the Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:thinning"

\end_inset

.
 We have thinned the observations by a factor of 20 and set 
\begin_inset Formula $a_{n}=0.1$
\end_inset

, thus preserving both good statistical power and correct calibration of
 p-values under the null hypothesis.
 In a general, we recommend to thin a chain so that 
\begin_inset Formula $Cor(X_{t},X_{t-1})<0.5$
\end_inset

, set 
\begin_inset Formula $a_{n}=0.1/k$
\end_inset

, and run test with at least 
\begin_inset Formula $max(500k,d100)$
\end_inset

 data points, where 
\begin_inset Formula $k<10$
\end_inset

, and d is data dimensionality
\begin_inset Foot
status open

\begin_layout Plain Layout
We recommend men should drink no more than 68 units of alcohol per week,
 no more than 34 units in any given day, and have at least 1 alcohol-free
 day.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/sgld_student_opt.pdf

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Thinned sample, suitable bootstrap.
 Most of the 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
auto-correlation within the sample is canceled by thinning.
 To guarantee that the remaining autocorrelation is handled properly, the
 flip probability is set at 
\begin_inset Formula $0.1$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\lang british

\begin_inset CommandInset label
LatexCommand label
name "fig:thinning"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Higher dimension and other one sample test.
\end_layout

\begin_layout Standard
In this experiment we make comparison with the test proposed by 
\begin_inset CommandInset citation
LatexCommand citep
key "BaringhausHenze88"

\end_inset

, which is basically MMD test for normality i.e.
 the null hypothesis is that 
\begin_inset Formula $Z$
\end_inset

 is d-dimensional standard normal random variable.
 Sample size was set to 500/1000, a_n=0.5.
 In this experiment we study power of the test and we generate 
\begin_inset Formula $Z$
\end_inset

 using the following procedure: 
\begin_inset Formula 
\[
Z\sim N(0,I_{d});Y\sim U[0,1];Z_{0}+=Y;
\]

\end_inset

 we modify only the first dimension.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Power-vs-Sample"

\end_inset

 shows power as a function of the sample size.
 Indeed, for high dimensions, if the expectation of the kernel exists in
 closed form, an MMD-type test like 
\begin_inset CommandInset citation
LatexCommand citep
key "BaringhausHenze88"

\end_inset

 is a better choice.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="8">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dim.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n=500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.86
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.29
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.24
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B&H
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n=1000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.87
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.62
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Stein
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n=500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.86
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.39
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n=1000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.77
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Power-vs-Sample"

\end_inset

Power vs Sample size for test by 
\begin_inset CommandInset citation
LatexCommand citep
key "BaringhausHenze88"

\end_inset

 and Stein based test.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Statistical Model Criticism on Gaussian Processes
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/gp_regression_data_fit.eps

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Fitted GP and data used to fit (blue) and to apply test (red).
\begin_inset CommandInset label
LatexCommand label
name "fig:experiment_gp_fit"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We next apply our test to the problem of statistical model criticism for
 GP regression.
 Our presentation and approach are similar to the non i.i.d.
\begin_inset space ~
\end_inset

case of 
\begin_inset CommandInset citation
LatexCommand citet
before "Section 6"
key "lloyd2015statistical"

\end_inset

.
 We use the 
\family typewriter
solar
\family default
 dataset, consisting of a 1D regression problem with 
\begin_inset Formula $N=402$
\end_inset

 pairs 
\begin_inset Formula $(X,y)$
\end_inset

.
 We fit 
\begin_inset Formula $N_{\text{train}}=361$
\end_inset

 data using a GP with a squared exponential kernel and a Gaussian noise
 model, and perform standard maximum likelihood II on the hyperparameters
 (length-scale, overall scale, noise-variance).
 We then apply our test to the remaining 
\begin_inset Formula $N_{\text{test}}=41$
\end_inset

 data.
 The test attempts to falsify the null hypothesis that the 
\family typewriter
solar
\family default
 dataset was generated from the plug-in predictive distribution (conditioned
 on training data and predicted position) of the GP.
 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "lloyd2015statistical"

\end_inset

 refer to this setup as non i.i.d., since the predictive distribution is a
 different univariate Gaussian for every predicted point.
 Our particular 
\begin_inset Formula $N_{\text{train}},N_{\text{test}}$
\end_inset

 were chosen to make sure the GP fit has stabilised, i.e.
\begin_inset space ~
\end_inset

adding more data did not cause further model refinement.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:experiment_gp_fit"

\end_inset

 shows training and testing data, and the fitted GP.
 Clearly, the Gaussian noise model is a poor fit for this particular dataset,
 e.g.
\begin_inset space ~
\end_inset

around 
\begin_inset Formula $X=-1$
\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:experiment_gp_test"

\end_inset

 shows the distribution over 
\begin_inset Formula $D=10000$
\end_inset

 bootstrapped V-statistics 
\begin_inset Formula $B_{n}$
\end_inset

 with 
\begin_inset Formula $n=N_{\text{test}}$
\end_inset

.
 The test statistic lies in an upper quantile of the bootstrapped null distribut
ion, indicating (correctly) that it is unlikely the test points were generated
 by the fitted GP model, even for the low number of test data observed,
 
\begin_inset Formula $N_{\text{test}}=41$
\end_inset

.
\end_layout

\begin_layout Standard
In a second experiment, we compare against 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "lloyd2015statistical"

\end_inset

: we compute the MMD statistic between test data 
\begin_inset Formula $(X_{\text{test}},y_{\text{test}})$
\end_inset

 and 
\begin_inset Formula $(X_{\text{test}},y_{\text{rep}})$
\end_inset

, where 
\begin_inset Formula $y_{\text{rep}}$
\end_inset

 are samples from the fitted GP.
 The null distribution is sampled from 10000 times via repeatedly sampling
 new 
\begin_inset Formula $\tilde{y}_{\text{rep}}$
\end_inset

 from the GP plug-in predictive posterior, and comparing 
\begin_inset Formula $(X_{\text{test}},\tilde{y}_{\text{rep}})$
\end_inset

 to 
\begin_inset Formula $(X_{\text{test}},y_{\text{rep}})$
\end_inset

.
 Averaged over 100 repetitions of randomly partitioning 
\begin_inset Formula $(X,y)$
\end_inset

 for training and testing, our goodness of fit test produces a p-value that
 is statistically not significantly different from the MMD method (
\begin_inset Formula $p\approx0.1$
\end_inset

, note that this result is subject to 
\begin_inset Formula $N_{\text{train}},N_{\text{test}}$
\end_inset

).
 We emphasize, however, that 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "lloyd2015statistical"

\end_inset

's test requires to sample from the fitted model (here 10000 null samples
 were required in order to achieve stable p-values).
 Our test 
\emph on
does not
\emph default
 sample from the GP at all and completely side-steps this highly costly
 approach.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/gp_regression_bootstrap_hist.eps
	scale 85

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Bootstrapped 
\begin_inset Formula $B_{n}$
\end_inset

 distribution with the test statistic 
\begin_inset Formula $V_{n}$
\end_inset

 marked.
\begin_inset CommandInset label
LatexCommand label
name "fig:experiment_gp_test"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*

\lang english
Approximate MCMC algorithm 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\lang english
\begin_inset Graphics
	filename img/Heiko1.pdf

\end_inset


\lang british

\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Distribution of p-values as a function of 
\begin_inset Formula $\epsilon$
\end_inset

 for austerity MCMC.
 
\begin_inset CommandInset label
LatexCommand label
name "p-values"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
We show how to quantify
\lang british
 bias-variance trade-offs in an approximate 
\lang english
MCMC algorithm
\lang british
 -- 
\lang english
austerity MCMC 
\begin_inset CommandInset citation
LatexCommand citep
key "korattikara2013austerity"

\end_inset


\lang british
.
 
\lang english
For the purpose of illustration we use a simple generative model from 
\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring,Welling2011"

\end_inset

, 
\begin_inset Formula 
\begin{align*}
\theta_{1}\sim N(0,10);\theta_{2}\sim N(0,1)\\
X_{i}\sim\frac{1}{2}N(\theta_{1},4)+\frac{1}{2}N(\theta_{2},4) & .
\end{align*}

\end_inset


\lang british

\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\lang english
\begin_inset Graphics
	filename img/Heiko2.pdf
	lyxscale 90

\end_inset


\lang british

\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Average number of likelihood evaluations a function of 
\begin_inset Formula $\epsilon$
\end_inset

 for austerity MCMC
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
(the y-axis is in millions of evaluations)
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\begin_inset CommandInset label
LatexCommand label
name "lik-evals"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\lang english
Austerity MCMC is a Monte Carlo procedure designed to reduce the number
 of likelihood evaluation in the acceptance step of the Metropolis-Hastings
 algorithm.
 The crux of method is to look at only a subset of the data, and make an
 acceptance/rejection decision based on this subset.
 The probability of making a wrong decision is proportional to a parameter
 
\begin_inset Formula $\epsilon\in[0,1]$
\end_inset

 .
 This parameter influences the time complexity of Austerity MCMC: when 
\begin_inset Formula $\epsilon$
\end_inset

 is larger, i.e., when there is a greater tolerance for error, the expected
 computational cost is lower.
 We simulated 
\begin_inset Formula $\{X_{i}\}_{1\leq i\leq400}$
\end_inset

 points from the model with 
\begin_inset Formula $\theta_{1}=0$
\end_inset

 and 
\begin_inset Formula $\theta_{2}=1$
\end_inset

.
 In this setting there were two modes in the posterior distribution: one
 at 
\begin_inset Formula $(0,1)$
\end_inset

 and the other at 
\begin_inset Formula $(1,-1)$
\end_inset

.
 We ran the Austerity algorithm with 
\begin_inset Formula $\epsilon$
\end_inset

 varying over the range 
\begin_inset Formula $[0.001,0.2]$
\end_inset

.
 For each 
\begin_inset Formula $\epsilon$
\end_inset

 we calculated an individual thinning factor, such that correlation between
 consecutive 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout

\lang english
elements of
\end_layout

\end_inset

 samples from the chains was smaller than 
\begin_inset Formula $0.5$
\end_inset

 (greater 
\begin_inset Formula $\epsilon$
\end_inset

 generally required more thinning).
 For each 
\begin_inset Formula $\epsilon$
\end_inset

 we tested the hypothesis that 
\begin_inset Formula $\{\theta_{i}\}_{1\leq i\leq500}$
\end_inset

 were drawn from the true stationary posterior, using our goodness of fit
 test.
 We generated 100 p-values for each 
\begin_inset Formula $\epsilon$
\end_inset

 , as shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "p-values"

\end_inset

.
 It is seems that 
\begin_inset Formula $\epsilon=0.4$
\end_inset

 yields a good approximation of the true stationary distribution, while
 being parsimonious in terms of likelihood evaluations, as shown in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "lik-evals"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection*
Convergence in non-parametric density estimation
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/increasing_data_fixed_test.eps
	lyxscale 90

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Density estimation: P-values for an increasing number of data 
\begin_inset Formula $N$
\end_inset

 for the non-parametric model.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:density_estimation_increasing_data"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In our final experiment, we apply our goodness of fit test to measuring
 quality-of-fit in nonparametric density estimation.
 We evaluate two density models: the infinite dimensional exponential family
 
\begin_inset CommandInset citation
LatexCommand citep
key "SriFukKumGreHyv14"

\end_inset

, and a recent approximation to this model using random Fourier features
 
\begin_inset CommandInset citation
LatexCommand citep
key "strathmann2015gradient"

\end_inset

.
 Our implementation of the model assumes the log density to take the form
 
\begin_inset Formula $f(x)$
\end_inset

, where 
\begin_inset Formula $f$
\end_inset

 lies in an RKHS induced by a Gaussian kernel with bandwidth 
\begin_inset Formula $1$
\end_inset

.
 We fit the model using 
\begin_inset Formula $N$
\end_inset

 observations drawn from a standard Gaussian, and performed our quadratic
 time test on a separate evaluation dataset of fixed size, 
\begin_inset Formula $N_{\text{test}}=500$
\end_inset

.
 Our goal was to identify 
\begin_inset Formula $N$
\end_inset

 sufficiently large that the goodness of fit test did not reject the null
 hypothesis (i.e., the model had learned the density sufficiently well, bearning
 in mind that it is guaranteed to converge for sufficiently large 
\begin_inset Formula $N$
\end_inset

).
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:density_estimation_increasing_data"

\end_inset

 shows how the distribution of p-values evolves as a function of 
\begin_inset Formula $N$
\end_inset

; this distribution is uniform for 
\begin_inset Formula $N=5000$
\end_inset

, but at 
\begin_inset Formula $N=500$
\end_inset

, the null hypothesis would very rarely be rejected.
\end_layout

\begin_layout Standard
We next consider the random fourier feature approximation to this model,
 where the log pdf, 
\begin_inset Formula $f$
\end_inset

, is approximated using a finite dictionary of random Fourier features 
\begin_inset CommandInset citation
LatexCommand citep
key "Rahimi2007"

\end_inset

.
 The natural question when using this approximation is: 
\begin_inset Quotes eld
\end_inset

How many random features do it I need?
\begin_inset Quotes erd
\end_inset

 Using the same test power 
\begin_inset Formula $N_{\text{test}}=500$
\end_inset

 as above, and a large number of available samples 
\begin_inset Formula $N=5\cdot10^{4}$
\end_inset

, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:density_estimation_increasing_features"

\end_inset

 shows the distributions of p-values for an increasing number of random
 features 
\begin_inset Formula $m$
\end_inset

.
 From about 
\begin_inset Formula $m=50$
\end_inset

, the null hypothesis would rarely be rejected, given a reasonable choice
 of test level.
 Note, however, that the p-values do 
\emph on
not
\emph default
 have a uniform distribution, even for a large number of random features.
 This subtle effect is caused by over-smoothing due to the regularisation
 approach taken in 
\begin_inset CommandInset citation
LatexCommand citep
after "KMC finite"
key "strathmann2015gradient"

\end_inset

, which would not otherwise have been detected.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
It vanishes when the estimator is not regularised, however, at the cost
 of numerical instability.
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/increasing_features_fixed_test.eps
	lyxscale 90

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Approximate density estimation: P-values for an increasing number of random
 features 
\begin_inset Formula $m$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:density_estimation_increasing_features"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "biblio"
options "icml2015"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
normalsize
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
onecolumn
\end_layout

\end_inset


\end_layout

\begin_layout Part*
Appendix
\end_layout

\begin_layout Section

\lang english
Proofs
\end_layout

\begin_layout Lemma

\lang english
\begin_inset CommandInset label
LatexCommand label
name "lem:easy"

\end_inset

 If a random variable 
\begin_inset Formula $X$
\end_inset

 is distributed according to 
\begin_inset Formula $p$
\end_inset

, under conditions on the kernel
\end_layout

\begin_layout Lemma

\lang english
\begin_inset Formula 
\begin{align*}
0 & =\oint_{\partial\mathcal{X}}k(x,x')q(x)n(x)dS(x'),\\
0 & =\oint_{\partial\mathcal{X}}\nabla_{x}k(x,x')^{\top}n(x')q(x')dS(x'),
\end{align*}

\end_inset

 and then for all 
\begin_inset Formula $f\in\mathcal{F}$
\end_inset

, the expected value of 
\begin_inset Formula $T$
\end_inset

 is zero, i.e.
 
\begin_inset Formula $\ev_{p}(Tf)(X)=0$
\end_inset

.
\end_layout

\begin_layout Proof

\lang english
This result was proved on bounded domains 
\begin_inset Formula $\mathcal{X}\subset\mathbb{R}^{d}$
\end_inset

 by 
\begin_inset CommandInset citation
LatexCommand citet
after "Lemma 1"
key "OatGirCho15"

\end_inset

, where 
\begin_inset Formula $n(x)$
\end_inset

 is the unit vector normal to the boundary at 
\begin_inset Formula $x$
\end_inset

, and 
\begin_inset Formula $\oint_{\partial\mathcal{X}}$
\end_inset

 is the surface integral over the boundary 
\begin_inset Formula $\partial\mathcal{X}$
\end_inset

.
 The case of unbounded domains was discussed by 
\begin_inset CommandInset citation
LatexCommand citet
after "Remark 2"
key "OatGirCho15"

\end_inset

.
 Here we provide an alternative, elementary proof for the latter case.
 First we show that the function
\begin_inset Formula $p\cdot f_{i}$
\end_inset

 vanishes at infinity, by which we mean that for all dimensions 
\begin_inset Formula $j$
\end_inset

 
\begin_inset Formula 
\[
\lim_{x_{j}\to\infty}p(x_{1},\cdots,x_{d})\cdot f_{i}(x_{1},\cdots,x_{d})=0.
\]

\end_inset

The density function 
\begin_inset Formula $p$
\end_inset

 vanishes at infinity.
 The function 
\begin_inset Formula $f$
\end_inset

 is bounded, which is implied by Cauchy-Schwarz inequality, 
\begin_inset Formula $\left|f(x)\right|\le\left\Vert f\right\Vert \sqrt{k(x,x)}$
\end_inset

.
 This implies that the function 
\begin_inset Formula $p\cdot f_{i}$
\end_inset

 vanishes at infinity.
 We check that the expected value 
\begin_inset Formula $\ev_{q}(T_{q})f(Z)$
\end_inset

 is zero.
 For all dimensions 
\begin_inset Formula $i$
\end_inset

 
\begin_inset Formula 
\begin{align*}
 & \ev_{p}\xi_{p}(X)\\
 & \ev_{p}\left(\frac{\partial\log p(X)}{\partial x_{i}}f_{i}(X)+\frac{\partial f_{i}(X)}{\partial x_{i}}\right)\\
 & =\int_{R_{d}}\left[\frac{\partial\log p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}\right]p(x)dx\\
 & =\int_{R_{d}}\left[\frac{1}{p(x)}\frac{\partial p(x)}{\partial x_{i}}f(x)+\frac{\partial f(x)}{\partial x_{i}}\right]p(x)dx\\
 & =\int_{R_{d}}\left[\frac{\partial p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}p(x)\right]dx\\
 & \overset{(a)}{=}\int_{R_{d-1}}\left(\lim_{R\to\infty}p(x)f_{i}(x)\bigg|_{x_{i}=-R}^{x_{i}=R}\right)dx_{1}\cdots dx_{i-1}\cdots dx_{i+1}\cdots d{x_{d}}\\
 & =\int_{R_{d-1}}0dx_{1}\cdots dx_{i-1}\cdots dx_{i+1}\cdots dx_{d}\\
 & =0.
\end{align*}

\end_inset

For the equation (a) we have used integration by parts, fact that 
\begin_inset Formula $p(x)f_{i}(x)$
\end_inset

 vanishes at infinity and Fubini-Toneli theorem to show that we can do iterated
 integration.
 The sufficient condition for the Fubini-Toneli theorem is that 
\begin_inset Formula $\ev_{q}\langle f,\xi_{p}(Z)\rangle^{2}<\infty$
\end_inset

.
 This is true since 
\begin_inset Formula $\ev_{p}\|\xi_{p}(X)\|^{2}\leq\ev_{p}h_{p}(X,X)<\infty$
\end_inset

.
 
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Proof

\lang english
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\lang english
Proof of 
\lang british
proposition
\lang english
 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm: null_dist"

\end_inset


\end_layout

\end_inset

We check assumptions of the Theorem 2.1 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

.
 The condition A1, 
\begin_inset Formula $\sum_{t=1}^{\infty}\sqrt{\tau(t)}\leq\infty$
\end_inset

, is implied by assumption 
\begin_inset Formula $\sum_{t=1}^{\infty}t^{2}\sqrt{\tau(t)}\leq\infty$
\end_inset

 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Details"

\end_inset

.
 Condition A2 (iv), Lipschitz continuity of 
\begin_inset Formula $h$
\end_inset

 is assumed.
 Conditions A2 i), ii) positive definiteness, symmetry and degeneracy of
 
\begin_inset Formula $h$
\end_inset

 follow from the proof of Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "theorem_discrepancy_is_metric"

\end_inset

.
 Indeed
\end_layout

\begin_layout Proof

\lang english
\begin_inset Formula 
\[
h_p(x,y)=\langle\xi_p(x),\xi_p(y)\rangle_{\mathcal{F}^{d}}
\]

\end_inset


\begin_inset Newline newline
\end_inset

so the statistic is an inner product and hence positive definite.
 Degeneracy under the null follows from the fact that, by Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:closed_form_discrepancy"

\end_inset

,
\begin_inset Formula $\ev_{q}\xi_p(Z)=0$
\end_inset

.
 Finally, condition A2 (iii), 
\begin_inset Formula $\ev_{p}h_p(X,X)\leq\infty$
\end_inset

 is assumed.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Proof

\lang english
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\lang english
Proof of 
\lang british
proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:wild_bootstrap_works"

\end_inset


\end_layout

\end_inset

We use Theorem 2.1 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

 to see that, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
under the null hypothesis, 
\begin_inset Formula $f(Z_{1,n},\cdots,Z_{t,n})$
\end_inset

 converges to zero in probability.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 The condition A1, 
\begin_inset Formula $\sum_{t=1}^{\infty}\sqrt{\tau(t)}\leq\infty$
\end_inset

, is implied by assumption 
\begin_inset Formula $\sum_{t=1}^{\infty}t^{2}\sqrt{\tau(t)}\leq\infty$
\end_inset

 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Details"

\end_inset

.
 Condition A2 (iv), Lipschitz continuity of 
\begin_inset Formula $h$
\end_inset

 is assumed..
 Assumption B1 is identical to our assumption 
\begin_inset Formula $\sum_{t=1}^{\infty}t^{2}\sqrt{\tau(t)}\leq\infty$
\end_inset

 from Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Details"

\end_inset

.
 Finally we check assumption B2 (bootstrap assumption):
\emph on
 
\begin_inset Formula $\{W_{t,n}\}_{1\leq t\leq n}$
\end_inset


\emph default
 is a row-wise strictly stationary triangular array independent of all 
\begin_inset Formula $Z_{t}$
\end_inset

 such that 
\begin_inset Formula $\ev W_{t,n}=0$
\end_inset

 and 
\begin_inset Formula $\sup_{n}\ev|W_{t,n}^{2+\sigma}|=1<\infty$
\end_inset

 for some 
\begin_inset Formula $\sigma>0$
\end_inset

.
 The auto-covariance of the process is given by 
\begin_inset Formula $\ev W_{s,n}W_{t,n}=(1-2p_{n})^{-|s-t|}$
\end_inset

, so the function 
\begin_inset Formula $\rho(x)=\exp(-x)$
\end_inset

, and 
\begin_inset Formula $l_{n}=\log(1-2p_{n})^{-1}$
\end_inset

.
 We verify that 
\begin_inset Formula $\lim_{u\to0}\rho(u)=1$
\end_inset

.
 If we set 
\begin_inset Formula $p_{n}=w_{n}^{-1}$
\end_inset

 , such that 
\begin_inset Formula $w_{n}=o(n)$
\end_inset

 and 
\begin_inset Formula $\lim_{n\to\infty}w_{n}=\infty$
\end_inset

, then 
\begin_inset Formula $l_{n}=O(w_{n})$
\end_inset

 and 
\begin_inset Formula $\sum_{r=1}^{n-1}\rho(|r|/l_{n})=\frac{1-(1-2p_{n})^{n+1}}{p_{n}}=O(w_{n})=O(l_{n})$
\end_inset

.
 We show that,under the alternative hypothesis, 
\begin_inset Formula $B_{n}$
\end_inset

 converges to zero - we use 
\begin_inset CommandInset citation
LatexCommand citep
after "Theorem 2"
key "chwialkowski2014wild"

\end_inset

, the only assumption 
\begin_inset Formula $\ensuremath{\tau(r)=o(r^{-4})}$
\end_inset

 is satisfied since 
\begin_inset Formula $\sum_{t=1}^{\infty}t^{2}\sqrt{\tau(t)}\leq\infty$
\end_inset

.
 We check the assumption 
\begin_inset Formula 
\[
\sup_{n}\sup_{i,j<n}\ev_{q}h_p(Z_{i},Z_{j})^{2}<\infty.
\]

\end_inset

We have 
\begin_inset Formula $\ev_{q}h_p(Z,Z')^{2}\leq\left(\ev_{q}\|\xi_p(Z)\|^{2}\right)^{2}=\left(\ev_{q}h_p(Z,Z)\right)^{2}<\infty$
\end_inset

 .
\end_layout

\begin_layout Proof

\lang english
We show that, under the alternative hypothesis, 
\begin_inset Formula $V_{n}$
\end_inset

 converges to a positive constant - we use 
\begin_inset CommandInset citation
LatexCommand citep
after "Theorem 3"
key "chwialkowski2014wild"

\end_inset

.
 The zero comportment of 
\begin_inset Formula $h$
\end_inset

 is positive since 
\begin_inset Formula $S_{p}^{2(Z)}>0$
\end_inset

.
 We checked the  assumption 
\begin_inset Formula $\sup_{n}\sup_{i,j<n}\ev_{q}h_p(Z_{i},Z_{j})^{2}<\infty$
\end_inset

 above.
\end_layout

\begin_layout Proof

\lang english
\begin_inset Note Note
status open

\begin_layout Proof

\lang english
It is sufficient to check that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\ev B_{n}\to0,\ev B_{n}^{2}\to0.$
\end_inset


\end_layout

\begin_layout Proof

\lang english
\begin_inset Formula 
\begin{align*}
\ev B_{n} & =\frac{1}{n^{2}}\sum_{i,j}\ev W_{i}W_{j}\ev_{q}h_p(Z_{i},Z_{j})\\
 & =\frac{1}{n^{2}}\sum_{i\in N^{m}}\rho(|j-i|/l_{n})\ev_{q}h_p(Z_{j},Z_{i})\\
 & \leq\frac{1}{n^{2}}\sum_{i\in N^{m}}|\rho(|j-i|/l_{n})C\\
 & \to0
\end{align*}

\end_inset


\lang british
for some constant 
\begin_inset Formula $C=\ev_{q}h_p(Z_{1},Z_{2})$
\end_inset

, whose existence follows from assumptions i) and iii).
 As for 
\begin_inset Formula $\ev B_{n}^{2}$
\end_inset

, we have
\end_layout

\begin_layout Proof

\lang english
\begin_inset Formula 
\begin{align*}
\ev B_{n}^{2} & =\frac{1}{n^{4}}\sum_{i,j,k,l}\ev W_{i}W_{j}W_{k}W_{l}\ev_{q}h_p(Z_{i},Z_{j})h_p(Z_{k},Z_{l})\\
 & \leq\frac{1}{n^{4}}\sum_{i\neq j,i\neq k,i\neq l,j\neq k,j\neq l,k\neq l}\ev W_{i}W_{j}W_{k}W_{l}\ev_{q}h_p(Z_{i},Z_{j})^{2}\ev_{q}h_p(Z_{k},Z_{l})^{2}+C'\frac{6n^{3}}{n^{4}}\\
 & \leq\frac{1}{n^{4}}\sum_{i\neq j,i\neq k,i\neq l,j\neq k,j\neq l,k\neq l}\ev W_{i}W_{j}W_{k}W_{l}C'+\frac{6C'}{n}\\
 & =\frac{6C'}{n}\to0,
\end{align*}

\end_inset


\lang british
where 
\begin_inset Formula $C'=\ev_{q}h_p(Z_{i},Z_{j})^{2}\ev_{q}h_p(Z_{k},Z_{l})^{2}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Note Note
status open

\begin_layout Plain Layout

\lang english
We may use similar reasoning for the quadratic time test to define a linear
 time test, based on the two-sample test of 
\begin_inset CommandInset citation
LatexCommand citet
key "Chwialkowski2015"

\end_inset

.
 For some fixed location 
\begin_inset Formula $y$
\end_inset

 and a random variable 
\begin_inset Formula $X$
\end_inset

, define a random variable 
\begin_inset Formula $s(X,y)$
\end_inset

 as 
\begin_inset Formula 
\begin{align}
s(X,y)=\nabla\log p(X)g(X,y)-\nabla g(X,y).
\end{align}

\end_inset

For some number of random locations 
\begin_inset Formula $Y_{1},Y_{J}$
\end_inset

 and a random variable 
\begin_inset Formula $X$
\end_inset

 define a random vector 
\begin_inset Formula $Z_{i}$
\end_inset

 
\begin_inset Formula 
\begin{equation}
Z_{i}=(s(X_{i},Y_{1}),\cdots,s(X_{i},Y_{J}))\in\mathbf{R}^{J}.
\end{equation}

\end_inset

Let 
\begin_inset Formula $W_{n}$
\end_inset

 be a mean of 
\begin_inset Formula $Z_{i}$
\end_inset

's 
\begin_inset Formula $W_{n}=\frac{1}{n}\sum_{i=1}^{n}Z_{i},$
\end_inset

 and 
\begin_inset Formula $\Sigma_{n}$
\end_inset

 its covariance matrix 
\begin_inset Formula $\Sigma_{n}=\frac{1}{n}ZZ^{T}$
\end_inset

.
 The test statistic is 
\begin_inset Formula 
\begin{equation}
S_{n}=nW_{n}\Sigma_{n}^{-1}W_{n}.
\end{equation}

\end_inset

The computation of 
\begin_inset Formula $S_{n}$
\end_inset

 requires inversion of a 
\begin_inset Formula $J\times J$
\end_inset

 matrix 
\begin_inset Formula $\Sigma_{n}$
\end_inset

, but this is fast and numerically stable: 
\begin_inset Formula $J$
\end_inset

 will typically be small, and is less than 10 in our experiments.
 The next proposition demonstrates the use of 
\begin_inset Formula $S_{n}$
\end_inset

 as a one-sample test.
\end_layout

\begin_layout Proposition

\lang english
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\lang english
Asymptotic behavior of 
\begin_inset Formula $S_{n}$
\end_inset


\end_layout

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "prop:Hotelling"

\end_inset

 If 
\begin_inset Formula $\ev_{p}s(X,y)=0$
\end_inset

 for all 
\begin_inset Formula $y$
\end_inset

, then the statistic 
\begin_inset Formula $S_{n}$
\end_inset

 is a.s.
 asymptotically distributed as a 
\begin_inset Formula $\chi^{2}$
\end_inset

-random variable with 
\begin_inset Formula $Jd$
\end_inset

 degrees of freedom, where 
\begin_inset Formula $d$
\end_inset

 is 
\begin_inset Formula $X$
\end_inset

 dimensionality (as 
\begin_inset Formula $n\to\infty$
\end_inset

 with 
\begin_inset Formula $d$
\end_inset

 fixed).
 If 
\begin_inset Formula $\ev_{p}s(X,y)\neq0$
\end_inset

 for almost all 
\begin_inset Formula $y$
\end_inset

 then a.s.
 for any fixed 
\begin_inset Formula $r$
\end_inset

, 
\begin_inset Formula $\mathbb{P}(S_{n}>r)\to1$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

 .
 
\end_layout

\begin_layout Paragraph

\lang english
One sample test
\end_layout

\begin_layout Plain Layout

\lang english
Calculate 
\begin_inset Formula $S_{n}$
\end_inset

.
 Choose a threshold 
\begin_inset Formula $r_{\alpha}$
\end_inset

 corresponding to the 
\begin_inset Formula $1-\alpha$
\end_inset

 quantile of a 
\begin_inset Formula $\chi^{2}$
\end_inset

 distribution with 
\begin_inset Formula $J$
\end_inset

 degrees of freedom, and reject the null hypothesis whenever 
\begin_inset Formula $S_{n}$
\end_inset

 is larger than 
\begin_inset Formula $r_{\alpha}$
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\begin_layout Section
MCMC convergence testing
\begin_inset CommandInset label
LatexCommand label
name "sec:MCMC-convergence-testing"

\end_inset


\end_layout

\begin_layout Paragraph
Convergence phase.
 
\end_layout

\begin_layout Standard
We only can show consistency during the convergence phase on the empirical
 data.
 During convergence phase the null hypothesis is not true, but can be 'almost'
 true.
 For a sequence 
\begin_inset Formula $Z_{i}$
\end_inset

 define the test statistic is 
\begin_inset Formula $\|S_{n}\|^{2},$
\end_inset

 where 
\begin_inset Formula $S_{n}=\frac{1}{\sqrt{}n}\sum_{i=1}^{n}\xi_{i,p}$
\end_inset

 
\begin_inset Formula 
\[
\ev\|S_{n}\|^{2}\geq\|\ev S_{n}\|^{2}>\frac{1}{n}\sum_{i,j}^{n}\langle\ev\xi_{i,p},\ev\xi_{i,p}\rangle
\]

\end_inset


\end_layout

\begin_layout Standard
If it is reasonable to assume that 
\begin_inset Formula $\ev\xi_{i,p}\simeq\ev\xi_{j,p}$
\end_inset

 the sum diverges, which makes the test consistent.
 One way to achieve 
\begin_inset Formula $\ev\xi_{i,p}=\ev\xi_{j,p}$
\end_inset

 it is to introduce an extra level of randomization i.e.
 sample the sequence without replacement and used the re-sampled sequence
 in the test.
 This may however change the structure of temporal dependence.
\end_layout

\begin_layout Paragraph
Stationary phase.
\end_layout

\begin_layout Standard
In the stationary phase there are number of results which might be used
 to show that the chain is 
\begin_inset Formula $\tau$
\end_inset

-mixing.
\end_layout

\begin_layout Paragraph
Strong mixing coefficients.
\end_layout

\begin_layout Standard
Strong mixing is historically the most studied type of temporal dependence
 -- a lot of models, example being Markov Chains, are proved to be strongly
 mixing, therefore it's useful to relate weak mixing to strong mixing.
\end_layout

\begin_layout Standard
A process is called absolutely regular (
\begin_inset Formula $\beta$
\end_inset

-mixing) if 
\begin_inset Formula $\beta(m)\rightarrow0$
\end_inset

, where 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta(m)=\frac{1}{2}\sup_{n}\sup\sum_{i=1}^{I}\sum_{j=1}^{J}|P(A_{i}\cap B_{j})-P(A_{i})P(B_{j})|.
\]

\end_inset


\end_layout

\begin_layout Standard
The second supremum in the 
\begin_inset Formula $\beta(m)$
\end_inset

 definition is taken over all pairs of finite partitions 
\begin_inset Formula $\{A_{1},\cdots,A_{I}\}$
\end_inset

 and 
\begin_inset Formula $\{B_{1},\cdots,B_{J}\}$
\end_inset

 of the sample space such that 
\begin_inset Formula $A_{i}\in\mathcal{A}_{1}^{n}$
\end_inset

 and 
\begin_inset Formula $B_{j}\in\mathcal{A}_{n+m}^{\infty}$
\end_inset

, and 
\begin_inset Formula $\mathcal{A}_{b}^{c}$
\end_inset

 is a sigma field spanned by a subsequence, 
\begin_inset Formula $\mathcal{A}_{b}^{c}=\sigma(X_{b},X_{b+1},...,X_{c})$
\end_inset

.
\end_layout

\begin_layout Standard
A process is called strongly mixing (
\begin_inset Formula $\alpha$
\end_inset

-mixing) if 
\begin_inset Formula $\alpha(m)\rightarrow0$
\end_inset

, where 
\begin_inset Formula 
\[
\alpha(m)=\sup_{n}\sup_{A\in\mathcal{A}_{1}^{n}}\sup_{B\in\mathcal{A}_{n+m}^{\infty}}|P(B\cap A)-P(B)P(A)|.
\]

\end_inset

 By 
\begin_inset CommandInset citation
LatexCommand citep
key "bradley_basic_2005"

\end_inset

 we have 
\begin_inset Formula $\alpha(m)\leq\beta(m)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Using another weak mixing coefficient 
\begin_inset Formula $\tilde{\alpha}(m)$
\end_inset

 we can relate strong mixing to weak mixing.
 The process is called 
\begin_inset Formula $\tilde{\alpha}$
\end_inset

-mixing if 
\begin_inset Formula $\tilde{\alpha}(m)\rightarrow0$
\end_inset

, where 
\begin_inset Formula 
\begin{align*}
\tilde{\alpha}(m) & =\sup_{l\in\mathbb{N}}\frac{1}{l}\sup_{m\leq i_{1}\leq...\leq i_{l}}\tilde{\alpha}(\mathcal{F}_{0},(X_{i_{1}},...,X_{i_{l}}))\overset{r\to\infty}{\longrightarrow}0,\;\text{where}\\
\tilde{\alpha}(\mathcal{M},X) & =\sup_{g\in\Lambda}\parallel\ev_{p}(g(X)|\mathcal{M})-\ev_{p}g(X)\parallel_{1}
\end{align*}

\end_inset

 and 
\begin_inset Formula $\Lambda$
\end_inset

 is the set of all one-Lipschitz continuous real-valued functions on the
 domain of 
\begin_inset Formula $X$
\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
after "Remark 2.4"
key "dedecker2007weak"

\end_inset

 show that 
\begin_inset Formula $\tilde{\alpha}(m)\leq2\alpha(m)$
\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
after "Proposition 2"
key "dedecker2005new"

\end_inset

 relates 
\begin_inset Formula $\tau$
\end_inset

-mixing and 
\begin_inset Formula $\tilde{\alpha}$
\end_inset

 mixing, as follows: if 
\begin_inset Formula $Q_{x}$
\end_inset

 is the generalized inverse of the tail function 
\begin_inset Formula 
\[
Q_{x}(u)=\inf_{t\in R}\{P(|X|>t)\leq u\},
\]

\end_inset

 then 
\begin_inset Formula 
\[
\tau(\mathcal{M},X)\leq2\int_{0}^{\tilde{\alpha}(\mathcal{M},X)}Q_{x}(u)du.
\]

\end_inset

 While this definition can be hard to interpret, it can be simplified in
 the case 
\begin_inset Formula $E|X|^{p}=M$
\end_inset

 for some 
\begin_inset Formula $p>1$
\end_inset

, since via Markov's inequality 
\begin_inset Formula $P(|X|>t)\leq\frac{M}{t^{p}}$
\end_inset

, and thus 
\begin_inset Formula $\frac{M}{t^{p}}\leq u$
\end_inset

 implies 
\begin_inset Formula $P(|X|>t)\leq u$
\end_inset

.
 Therefore 
\begin_inset Formula $Q'(u)=\frac{M}{\sqrt[p]{u}}\geq Q_{x}(u)$
\end_inset

.
 As a result, we have the following inequality 
\begin_inset Formula 
\[
\frac{\sqrt[p]{\tilde{\alpha}(\mathcal{M},X)}}{M}\geq C\tau(\mathcal{M},X).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "dedecker2005new"

\end_inset

 provides examples of systems that are tau-mixing.
 In particular, given that certain assumptions are satisfied causal functions
 of stationary sequences, iterated random functions, Markov chains, expanding
 maps are all $
\backslash
tau$-mixing.
 
\end_layout

\begin_layout Standard
Of particular interest to this work are Markov chains.
 The assumptions provided by 
\begin_inset CommandInset citation
LatexCommand citep
key "dedecker2005new"

\end_inset

, under which Markov chains are tau-mixing are somehow difficult to check
 but we can use classical theorems about the absolute regularity (beta mixing).
 In particular 
\begin_inset CommandInset citation
LatexCommand citep
after "Corollary 3.6"
key "bradley_basic_2005"

\end_inset

 states that a Harris recurrent and aperiodic Markov chain satisfies absolute
 regularity and 
\begin_inset CommandInset citation
LatexCommand citep
after "Theorem 3.7"
key "bradley_basic_2005"

\end_inset

 states that geometric ergodicity implies geometric decay of the 
\begin_inset Formula $\beta$
\end_inset

 coefficient.
 Interestingly 
\begin_inset CommandInset citation
LatexCommand citep
after "Theorem 3.2"
key "bradley_basic_2005"

\end_inset

 describes situations in which a non-stationary chain 
\begin_inset Formula $\beta$
\end_inset

-mixes exponentially.
 
\end_layout

\begin_layout Standard
Using inequalities between 
\begin_inset Formula $\tau$
\end_inset

-mixing coefficient and strong mixing coefficients one can use those classical
 theorems show that e.g Markov chains are 
\begin_inset Formula $\tau$
\end_inset

-mixing sequences.
\end_layout

\end_body
\end_document

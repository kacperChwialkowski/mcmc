#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass scrartcl
\begin_preamble
% from the icml 2016 example tex file
\usepackage{times}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{icml2016} 

%\usepackage[accepted]{icml2016}


\newcommand{\heiko}[1]{   {\bf \color{blue}{HS: #1}}  }
\newcommand{\kacper}[1]{   {\bf \color{red}{K: #1}}  }
\newcommand{\arthur}[1]{   {\bf \color{magenta}{AG: #1}}  }

%\newcommand{\heiko}[1]{}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
theorems-sec
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
twocolumn[ 
\backslash
icmltitle{A Kernel Test of Goodness of Fit}
\end_layout

\begin_layout Plain Layout

% It is OKAY to include author information, even for blind
\end_layout

\begin_layout Plain Layout

% submissions: the style file will automatically remove it for you
\end_layout

\begin_layout Plain Layout

% unless you've provided the [accepted] option to the icml2015
\end_layout

\begin_layout Plain Layout

% package.
\end_layout

\begin_layout Plain Layout


\backslash
icmlauthor{Kacper Chwialkowski$^*$}{kacper.chwialkowski@gmail.com}
\end_layout

\begin_layout Plain Layout


\backslash
icmlauthor{Heiko Strathmann$^*$}{heiko.strathmann@gmail.com}
\end_layout

\begin_layout Plain Layout


\backslash
icmlauthor{Arthur Gretton}{arthur.gretton@gmail.com}
\end_layout

\begin_layout Plain Layout


\backslash
icmladdress{Gatsby Unit, University College London, United Kingdom}
\end_layout

\begin_layout Plain Layout

% You may provide any keywords that you 
\end_layout

\begin_layout Plain Layout

% find helpful for describing your paper; these are used to populate
\end_layout

\begin_layout Plain Layout

% the "keywords" metadata in the PDF but will not be shown in the document
\end_layout

\begin_layout Plain Layout


\backslash
icmlkeywords{kernel methods, goodness-of-fit, Stein's method, statistical
 testing}
\end_layout

\begin_layout Plain Layout


\backslash
vskip 0.3in ]
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Abstract
We propose a nonparametric statistical test for goodness-of-fit: given a
 set of samples from an input probability density function, the test determines
 how likely it is that these were generated from a target density.
 The measure of goodness of fit 
\begin_inset Note Note
status open

\begin_layout Plain Layout
uses the largest expectation over a class of functions to determine the
 distance from the input density to the target density,
\end_layout

\end_inset

 is an integral probability metric constructed from a reproducing kernel
 Hilbert space via Stein's method.
 Our test statistic is an unbiased empirical estimate of this measure, taking
 the form of a simple U-statistic in terms of the log gradients of the target
 and the kernel.
 We derive a statistical test, both for i.i.d.
 and non-i.i.d.
 samples, where in the latter setting we propose a wild bootstrap procedure.
 We apply our test to quantifying convergence of approximate Markov Chain
 Monte Carlo methods, statistical model critisism, and evaluating quality
 of fit vs model complexity in nonparametric density estimation.
\end_layout

\begin_layout Abstract
\begin_inset Note Note
status open

\begin_layout Plain Layout
We present a nonparametric goodness-of-fit test.
 Given a set of samples, the test allows to quantify how likely it is that
 the samples have been generated from a given probability density function.
 We use Stein operators in Reproducing Kernel Hilbert Spaces to construct
 a divergence metric that that solely depends on the log-gradients of the
 target density.
 The metric has a simple form and can be efficiently estimated from data.
 We analyse the estimator's asymptotic properties, and embed it into the
 framwork of statistical hypothesis testing -- including efficient test
 constructions using non iid data.
 As a demonstration of the test's practicality, we apply it to quantifying
 convergence of approximate Markov Chain Monte Carlo methods, statistical
 model critisism, and assessing estimation and approximation convergence
 in non-parametric density estimation.
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset FormulaMacro
\newcommand{\ev}{\mathbb{E}}
{\mathbb{E}}
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Goodness-of-it testing, or measure sampling quality, is a fundamental tool
 in statistical analysis 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
heiko{reference}
\end_layout

\end_inset

.
 Given a set of random realisation 
\begin_inset Formula $\{x_{i}\}_{i=1}^{n}$
\end_inset

 of a random variable 
\begin_inset Formula $X\sim p$
\end_inset

 with distribution 
\begin_inset Formula $p$
\end_inset

, researchers are often interested in the question whether 
\begin_inset Formula $p$
\end_inset

 matches some reference distribution 
\begin_inset Formula $q$
\end_inset


\lang english
, which is in our case assumed to have a density wrt the Lebesgue measure,
 
\begin_inset Formula $dq(x)=q(x)dx$
\end_inset

, and which we assume to be known up to the normalisation constant.
 While the problem is well studied for certain parametric families, e.g.
 Gaussian 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
heiko{reference, also add more examples}
\end_layout

\end_inset

, it is more challenging in the nonparametric context.
\end_layout

\begin_layout Standard

\lang english
Recently, 
\lang british

\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring"

\end_inset

 proposed an elegant construction to measure sample quality by quantifying
 the maximum discrepancy between empirical sample expectations and target
 expectations for a large class of test functions.
 The method is based on the so-called 
\emph on
Stein operator
\emph default
 on the test function, whose application produces vanishing expectation
 under 
\begin_inset Formula $q$
\end_inset

, and which only depends on the derivarive of the 
\begin_inset Formula $\log q$
\end_inset

.
 It therefore allows for construction of a discrepancy metric that can be
 computed 
\emph on
without
\emph default
 requiring samples from 
\begin_inset Formula $q$
\end_inset

, but only the 
\begin_inset Formula $\{x_{i}\}_{i=1}^{n}$
\end_inset

 .
\end_layout

\begin_layout Standard
Computation of the Stein operator in 
\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring"

\end_inset

 is based on solving an expensive linear program that arises from a complicated
 construction of graph Stein discrepancies and geometric spanners.
 Their metric furthermore requires access to nontrivial lower bounds that,
 despite being provided for log-concave densities, are a largely open problem
 otherwise, in particular for multivariate cases.
 In addition, the lack of asymptotic analysis of their estimator makes it
 extremely hard to quantify cases when it detects a 
\emph on
significant
\emph default
 difference between samples and reference distribution.
 This in particular is holds the samples exhibit correlation structure.
\end_layout

\begin_layout Standard
The key contribution of this work is two-fold.
 First, we express the Stein operator as an inner product in a Reproducing
 Kernel Hilbert Space (RKHS), which results in a simple form that is straight-fo
rward and cheap to estimate from data.
 Second, we analyse asymptotic properties of our estimator and embed it
 into the statistical hypothesis testing framework.
 This allows us to quantify significance of the estimated divergence.
 We furthermore cover the important case of testing using correlated data.
 The result is a mathematically and computationally simple, nonparametric
 goodness-of-fit test, that only relies on the gradients on the log-density,
 and that can be applied to non-iid data.
\end_layout

\begin_layout Standard
The last point is useful in a highly interesting application of goodness-of-fit
 tests: approximate Markov Chain Monte Carlo (MCMC) 
\begin_inset CommandInset citation
LatexCommand citep
key "Korattikara2014,Welling2011,Bardenet2014"

\end_inset

.
 With the hope to increase the overall efficiency, these methods use modificatio
ns to Markov transition kernels that improve mixing speed at the cost of
 introducing an asymptotic bias.
 Such bias-variance trade-offs can usually be tuned with paramters of the
 sampling algorithms.
 It is therefore an important question whether for a particular parameter
 setting and for a fixed run-time, the produced samples have increased in
 quality or not.
 This question cannot be answered with classical MCMC convergence statistics
 alone -- those assume that the Markov chain reaches its equilibrium distributio
n.
 The described goodness-of-fit testing framework, however, fits very well
 into this context as it exactly quantifies the asymptotic bias of approximate
 MCMC, and furthermore only requires access to the 
\emph on
unnormalised
\emph default
 log density function.
 Additional challenge comes from the fact that MCMC samples exhibit correlation
 structure that has a potentially severe impact on asymptotic properties
 of statistical tests.
 In order to overcome such problems in our test, we apply the 
\emph on
wild-bootstrap
\emph default
 technique 
\begin_inset CommandInset citation
LatexCommand citep
key "chwialkowski2014wild,Shao2010,leucht_dependent_2013"

\end_inset

, which leads to correctly calibrated test asymptotics even for non iid
 data.
\end_layout

\begin_layout Section

\lang english
Kernel One Sample Test
\end_layout

\begin_layout Standard

\lang english
In the following section we derive a kernel one sample test.
 The test is applicable to family of distributions, on a real coordinate
 space, 
\begin_inset Formula $\mathcal{P}$
\end_inset

, where distributions 
\begin_inset Formula $p\in\mathcal{P}$
\end_inset

 satisfy two conditions: 
\begin_inset Newline newline
\end_inset

 (i) 
\begin_inset Formula $\nabla\log p(x)$
\end_inset

 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
is Lipschitz continuous
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
; 
\begin_inset Newline newline
\end_inset

 (ii) 
\begin_inset Formula $\ev\|\nabla\log p(Z)\|^{2}\leq\infty$
\end_inset

 for any random variable 
\begin_inset Formula $Z$
\end_inset

.
\begin_inset Newline newline
\end_inset

 The kernels considered in this work are assumed to be bounded, symmetric
 and cc-universal 
\begin_inset CommandInset citation
LatexCommand citep
key "SriFukLan11"

\end_inset

.
 On top of that we assume that any kernel 
\begin_inset Formula $k$
\end_inset

 must satisfy 
\begin_inset Newline newline
\end_inset

 (iii) 
\begin_inset Formula $\ev\left(\frac{\partial^{2}k(Z,Z)}{dx_{i}dx_{i+d}}\right)^{2}<\infty$
\end_inset

, for any random variable 
\begin_inset Formula $Z$
\end_inset

,
\begin_inset Newline newline
\end_inset

(iv)
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\nabla k(x,y)$
\end_inset

 is Lipschitz continuous.
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Newline newline
\end_inset

We denote by 
\begin_inset Formula $\mathcal{F}$
\end_inset

 the Reproducing Kernel Hilbert Space associated with the kernel 
\begin_inset Formula $k$
\end_inset

.
\end_layout

\begin_layout Paragraph

\lang english
Stein operator.
\end_layout

\begin_layout Standard

\lang english
We proceed similarly to 
\begin_inset CommandInset citation
LatexCommand citet
key "stein1972,gorham2015measuring"

\end_inset

 and make use of a Stein operator to characterize discrepancy between probabilit
y measures.
 Following 
\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring"

\end_inset

, we study the operator 
\begin_inset Formula $T_{p}$
\end_inset

 acting on 
\begin_inset Formula $R^{d}$
\end_inset

 valued functions 
\begin_inset Formula $f=(f_{1},\cdots,f_{d})$
\end_inset

, 
\begin_inset Formula $f_{i}\in\mathcal{F}$
\end_inset

 
\begin_inset Formula 
\[
T_{p}f=\sum_{i=1}^{d}\left(\frac{\partial\log p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}\right).
\]

\end_inset

As in 
\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring"

\end_inset

, we show that for all 
\begin_inset Formula $f\in F^{d},\ev(T_{q}f)(X)=0$
\end_inset

 (Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:easy"

\end_inset

).
 Next, for any random variable 
\begin_inset Formula $Z$
\end_inset

, we define Stein discrepancy between 
\begin_inset Formula $X\sim p$
\end_inset

 and 
\begin_inset Formula $Z$
\end_inset

 
\begin_inset Formula 
\begin{alignat}{1}
S(Z,\mathcal{F},p) & =\sup_{f\in F^{d},\|f\|<1}\ev(T_{p}f)(Z)\label{eq:Sdef}\\
 & =\sup_{f\in F^{d}}\ev(T_{p}f)(Z)-\ev(T_{p}f)(X).\nonumber 
\end{alignat}

\end_inset

In Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th2"

\end_inset

 we show that 
\begin_inset Formula $S(Z,\mathcal{F},p)$
\end_inset

 captures any difference between probability measures.
 Contrary to 
\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring"

\end_inset

, we don't need to approximate 
\begin_inset Formula $S(Y,\mathcal{F},p)$
\end_inset

 -- we can calculate it explicitly, as demonstrated in the Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th1"

\end_inset

.
 We start with a definition of a function 
\begin_inset Formula $\xi$
\end_inset

, which expected value can be interpreted as a type of a mean embedding.
 
\end_layout

\begin_layout Definition

\lang english
For any 
\begin_inset Formula $x\in R^{d}$
\end_inset

, define a vector valued function function 
\begin_inset Formula $\xi:R^{d}\to R^{d}$
\end_inset

, 
\begin_inset Formula 
\[
\xi(x,t)=\left[\nabla\log p(x)k(x,t)+\nabla_{1}k(x,t)\right]
\]

\end_inset

where 
\begin_inset Formula $\nabla\log p(x)=\left(\frac{\partial\log p(x)}{\partial x_{1}},\cdots,\frac{\partial\log p(x)}{\partial x_{d}}\right)$
\end_inset

 and 
\begin_inset Formula $\nabla_{1}k(x,t)=\left(\frac{\partial k(x,t)}{\partial x_{1}},\cdots,\frac{\partial k(x,t)}{\partial x_{d}}\right)$
\end_inset

.
 
\end_layout

\begin_layout Lemma

\lang english
\begin_inset CommandInset label
LatexCommand label
name "lem:WellDefined"

\end_inset

 
\begin_inset Formula $\xi(x,\cdot)$
\end_inset

 is an element of the reproducing kernel Hilbert space 
\begin_inset Formula $\mathcal{F}^{d}$
\end_inset

.
 
\end_layout

\begin_layout Proof

\lang english
We use the proof on p.
 132 of 
\begin_inset CommandInset citation
LatexCommand citet
after "Corollary 4.36"
key "SteChr08"

\end_inset

 to see that for all 
\begin_inset Formula $x\in R^{d}$
\end_inset

 each entry of 
\begin_inset Formula $\nabla_{1}k(x,\cdot)$
\end_inset

 belongs to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 
\begin_inset Formula $\frac{\partial\log p(x)}{\partial x_{i}}k(x,\cdot)\in\mathcal{F}$
\end_inset

, since 
\begin_inset Formula $k(x,\cdot)\in\mathcal{F}$
\end_inset

 and 
\begin_inset Formula $\frac{\partial\log p(x)}{\partial x_{i}}$
\end_inset

 is a scalar.
 
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
The following technical lemma shows that the expected value of 
\begin_inset Formula $\xi$
\end_inset

 is well defined -- it is needed for establishing a link between Stain operator
 
\begin_inset Formula $T_{p}f$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset

.
\end_layout

\begin_layout Lemma

\lang english
\begin_inset CommandInset label
LatexCommand label
name "lem:BochnerInt1"

\end_inset

For any random variable 
\begin_inset Formula $Z$
\end_inset

, expected value of 
\begin_inset Formula $\xi(Z)$
\end_inset

 is is element of 
\begin_inset Formula $\mathcal{F}^{d}$
\end_inset

 (
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\xi$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is Bochner integrable wrt measure of 
\begin_inset Formula $Z$
\end_inset

).
 
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
Now we can show that the expected value of the Stain operator is a functional
 on the RKHS 
\begin_inset Formula $\mathcal{F}^{d}$
\end_inset

, hence it coincidences with a inner product with some element of 
\begin_inset Formula $\mathcal{F}^{d}$
\end_inset

.
 This element turns out to be the expected value of 
\begin_inset Formula $\xi$
\end_inset

.
 
\end_layout

\begin_layout Lemma

\lang english
\begin_inset CommandInset label
LatexCommand label
name "lem:SteinIsInner"

\end_inset

For any random variable 
\begin_inset Formula $Z$
\end_inset

, expected value of Stein operator coincides with inner product of 
\begin_inset Formula $f$
\end_inset

 and expected value of 
\begin_inset Formula $\xi(Z)$
\end_inset

 i.e.
 
\begin_inset Formula 
\begin{align*}
\ev T_{p}f(Z)=\langle f,\ev\xi(Z)\rangle_{\mathcal{F}^{d}} & =\sum_{i=1}^{d}\langle f_{i},\ev\xi_{i}(Z)\rangle_{\mathcal{F}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof

\lang english
We write
\begin_inset Formula 
\begin{align*}
 & \left\langle f_{i},\ev\xi_{i}(Z)\right\rangle _{\mathcal{F}}\\
 & =\left\langle f_{i},\ev\left[\frac{\partial\log p(Z)}{\partial x_{i}}k(Z,\cdot)+\frac{\partial k(Z,\cdot)}{\partial x_{i}}\right]\right\rangle _{\mathcal{F}}\\
 & =\ev\left\langle f_{i},\frac{\partial\log p(Z)}{\partial x_{i}}k(Z,\cdot)+\frac{\partial k(Z,\cdot)}{\partial x_{i}}\right\rangle _{\mathcal{F}}\\
 & =\ev\left[\frac{\partial\log p(Z)}{\partial x_{i}}f_{i}(Z)+\frac{\partial k(Z,\cdot)}{\partial x_{i}}\right].
\end{align*}

\end_inset

The second equality follows form the fact that linear operator 
\begin_inset Formula $\langle f_{i},\cdot\rangle_{\mathcal{F}}$
\end_inset

 can be interchanged with Bochner integral and the fact that 
\begin_inset Formula $\xi$
\end_inset

 is Bochner integrable (Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:BochnerInt1"

\end_inset

).
 The last equality is an application of reproducing property.
 
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
By the construction of the Stain operator we know that for 
\begin_inset Formula $X\sim p$
\end_inset

, 
\begin_inset Formula $\ev(T_{p}f)(X)=0$
\end_inset

, and so for any random variable 
\begin_inset Formula $Z$
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{align*}
S(Y,\mathcal{F},p) & =\sup_{f\in F^{d}}\ev(T_{p}f)(Y)-\ev(T_{p}f)(X)\\
 & =\sup_{f\in F^{d}}\langle f,\ev\xi(Y)-\ev\xi(X)\rangle_{\mathcal{F}^{d}}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This illustrates intuition 
\begin_inset Formula $\ev\xi(Z)$
\end_inset

 is a type of mean embedding centred at the measure 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Lemma

\lang english
Discrepancy 
\begin_inset Formula $S(Y,\mathcal{F},p)$
\end_inset

 is maximized by an expected value of 
\begin_inset Formula $\xi$
\end_inset

, 
\begin_inset Formula $S(Y,\mathcal{F},p)=\|\ev\xi(Y)\|$
\end_inset

.
\end_layout

\begin_layout Proof

\lang english
By the Lemma 
\lang british

\begin_inset CommandInset ref
LatexCommand ref
reference "lem:SteinIsInner"

\end_inset

, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $\ev T_{p}f(Y)=\langle f,\ev\xi(Y)\rangle$
\end_inset

, therefore 
\begin_inset Formula $S(Y,\mathcal{F},p)$
\end_inset

 is maximized by 
\begin_inset Formula $\frac{\ev\xi(Y)}{\|\ev\xi(Y)\|}$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
We are ready to write down the closed form formula for 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $S(Y,\mathcal{F},p)^{2}$
\end_inset

.
 The proof, which is mostly an algebraic manipulation, is in the appendix.
 
\end_layout

\begin_layout Theorem

\lang english
\begin_inset CommandInset label
LatexCommand label
name "th1"

\end_inset

 
\begin_inset Formula $S(Y,\mathcal{F},p)^{2}$
\end_inset

 can be written in a closed form.
 
\begin_inset Formula 
\begin{align*}
 & \quad\ev\langle\nabla\log p(X_{1}),\nabla\log p(X_{2})\rangle_{2}k(X_{1},X_{2})\\
 & \quad+\ev\langle\nabla p(X_{2}),\nabla_{1}k(X_{1},X_{2})\rangle_{2}\\
 & \quad+\ev\langle\nabla\log p(X_{1}),\nabla_{2}k(X_{1},X_{2})\rangle_{2}\\
 & \quad+\ev\ \langle\nabla_{1}k(X_{1},X_{2}),\nabla_{2}k(X_{1},X_{2})\rangle_{2},
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem

\lang english
where 
\begin_inset Formula $\nabla_{2}k(x,y)=\left(\frac{\partial k(x,y)}{\partial y_{1}},\cdots,\frac{\partial k(x,y)}{\partial y_{d}}\right).$
\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
Finally we prove that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $S$
\end_inset

 discriminates different probability measures.
 
\end_layout

\begin_layout Theorem

\lang english
\begin_inset CommandInset label
LatexCommand label
name "th2"

\end_inset

 Suppose 
\begin_inset Formula $q,p\in\mathcal{P}$
\end_inset

 and let 
\begin_inset Formula $Y\sim q$
\end_inset

.
 
\begin_inset Formula $S(Y,\mathcal{F},p)=0$
\end_inset

 if and only if 
\begin_inset Formula $p=q$
\end_inset

.
 
\end_layout

\begin_layout Proof

\lang english
If 
\begin_inset Formula $p=q$
\end_inset

 then 
\begin_inset Formula $S(Y,\mathcal{F},p)=0$
\end_inset

 by the Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:easy"

\end_inset

.
 Suppose 
\begin_inset Formula $p\neq q$
\end_inset

, but 
\begin_inset Formula $S(Y,\mathcal{F},p)=0$
\end_inset

.
 If 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $S(Y,\mathcal{F},p)=0$
\end_inset

 then 
\begin_inset Formula $\ev\xi(Y)=0.$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 For each dimension of 
\begin_inset Formula $\ev\xi(Y)$
\end_inset

 we add and subtract 
\begin_inset Formula $\log q(Y)$
\end_inset

 
\begin_inset Formula 
\begin{align*}
 & \ev\left(\frac{\partial}{\partial x_{i}}\log p(Y)k(Y,\cdot)+\frac{\partial}{\partial x_{i}}k(Y,\cdot)\right)\\
 & =\ev\left(\frac{\partial}{\partial x_{i}}(\log q(Y))k(Y,\cdot)+\frac{\partial}{\partial x_{i}}k(Y,\cdot)\right)\\
 & \quad+\ev\left(\frac{\partial}{\partial x_{i}}(\log p(Y)-\log q(Y))k(Y,\cdot)\right).
\end{align*}

\end_inset

We have used Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:easy"

\end_inset

 to see that 
\begin_inset Formula 
\[
\ev\left(\frac{\partial}{\partial x_{i}}(\log q(Y))k(Y,\cdot)+\frac{\partial}{\partial x_{i}}k(Y,\cdot)\right)=0.
\]

\end_inset

We recognize that expected value of random 
\begin_inset Formula $\frac{\partial}{\partial x_{i}}(\log p(Y)-\log q(Y))k(Y,\cdot)$
\end_inset

 is mean emending of a function 
\begin_inset Formula $g(y)=\frac{\partial}{\partial x_{i}}\left(\log\frac{p(y)}{q(y)}\right)$
\end_inset

 with respect to the measure 
\begin_inset Formula $q$
\end_inset

.
 Since kernel 
\begin_inset Formula $k$
\end_inset

 is cc-universal this embedding is zero if and only if 
\begin_inset Formula $g=0$
\end_inset

 which implies that 
\begin_inset Formula 
\[
\nabla\log\frac{p(y)}{q(y)}=(0,\cdots,0)
\]

\end_inset

A constant vector filed of derivatives can be generated only by a constant
 functions, so 
\begin_inset Formula $\log\frac{p(y)}{q(y)}=C$
\end_inset

, for some 
\begin_inset Formula $C$
\end_inset

, which implies that 
\begin_inset Formula $p(y)=e^{C}q(y)$
\end_inset

.
 Since 
\begin_inset Formula $p$
\end_inset

 and 
\begin_inset Formula $q$
\end_inset

 integrates to one 
\begin_inset Formula $C=0$
\end_inset

 and so 
\begin_inset Formula $p=q$
\end_inset

.
 
\end_layout

\begin_layout Section

\lang english
Test
\end_layout

\begin_layout Standard

\lang english
Basic two concepts required for derivation of the test statistic is 
\begin_inset Formula $\tau$
\end_inset

-mixing 
\begin_inset CommandInset citation
LatexCommand cite
key "dedecker2007weak"

\end_inset

, and 
\begin_inset Formula $V$
\end_inset

-statistics 
\begin_inset CommandInset citation
LatexCommand citet
key "serfling80"

\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula $\tau$
\end_inset

-mixing is a notion of dependence within the observations, weak enough for
 most practical applications.
 Trivially, iid observations are 
\begin_inset Formula $\tau$
\end_inset

-mixing.
 As for the Markov Chains, which convergance we study in the experiments,
 the property of geometric ergodicity implies 
\begin_inset Formula $\tau$
\end_inset

-mixing (given that the stationary distribution has a finite moment, see
 appendix B of 
\begin_inset CommandInset citation
LatexCommand citet
key "chwialkowski2014kernel"

\end_inset

).
 To introduce 
\begin_inset Formula $\tau$
\end_inset

-mixing formally, let 
\begin_inset Formula $\{X_{t},\mathcal{F}_{t}\}_{t\in\mathbb{N}}$
\end_inset

 be a stationary sequence of integrable random variables, with respect to
 a natural filtration 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

.
 The sequence is called 
\begin_inset Formula $\tau$
\end_inset

-dependent if 
\begin_inset Formula $\tau(r)$
\end_inset

 converges to zero with 
\begin_inset Formula $r$
\end_inset

 going to infinity, where 
\begin_inset Formula $\tau$
\end_inset

 is defined as follows 
\begin_inset Formula 
\begin{align*}
\tau(r) & =\sup_{l\in\mathbb{N}}\frac{1}{l}\sup_{r\leq i_{1}...\leq i_{l}}T(\mathcal{F}_{0},(X_{i_{1}},...,X_{i_{l}})),\\
T(\mathcal{M},X) & =\ev\left(\sup_{g\in\Lambda}\left|\int g(t)(dP_{X|\mathcal{M}}-dP)\right|\right)
\end{align*}

\end_inset

and 
\begin_inset Formula $\Lambda$
\end_inset

 is the set of all one-Lipschitz continuous real-valued functions on the
 domain of 
\begin_inset Formula $X$
\end_inset

.
 For this work we will assume a technical condition 
\begin_inset Formula $\tau(t)\leq O(t^{-6})$
\end_inset

.
 A 
\begin_inset Formula $V$
\end_inset

-statistic of a function 
\begin_inset Formula $h,$
\end_inset

 is defined as follows
\begin_inset Formula 
\[
V_{n}(h,X)=\frac{1}{n}\sum_{i,j=1}^{n}h(X_{i},X_{j}).
\]

\end_inset

For the one sample test the function 
\begin_inset Formula $h$
\end_inset

 is 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{align*}
h(x,y) & =\langle\nabla\log p(X_{1}),\nabla\log p(X_{2})\rangle_{2}k(X_{1},X_{2})\\
 & +\langle\nabla p(X_{2}),\nabla_{1}k(X_{1},X_{2})\rangle_{2}\\
 & +\langle\nabla\log p(X_{1}),\nabla_{2}k(X_{1},X_{2})\rangle_{2}\\
 & +\langle\nabla_{1}k(X_{1},X_{2}),\nabla_{2}k(X_{1},X_{2})\rangle_{2}.
\end{align*}

\end_inset

The distribution of 
\begin_inset Formula $V(h,X)$
\end_inset

 depends whether 
\begin_inset Formula $X\sim p$
\end_inset

 or not.
 This is illustrated by the following theorem, which is a direct application
 of the Theorem 2.1 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset


\end_layout

\begin_layout Theorem

\lang english
\begin_inset CommandInset label
LatexCommand label
name "thm: null_dist"

\end_inset

If 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $X\sim p$
\end_inset

 then 
\begin_inset Formula $V_{n}(h,X)$
\end_inset

 converges weakly to some distribution.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
Proof, which is a simple verification of the assumptions, is in the appendix.
 Although a formula for a limit distribution of 
\family default
\series bold
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $V_{n}(h,X)$
\end_inset


\family roman
\series medium
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 can be derived explicitly ( 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
Theorem 2.1
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

), we do provide it here.
 To our knowledge there are no methods of obtaining quintiles of a limit
 of 
\family default
\series bold
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $V_{n}(h,X)$
\end_inset


\family roman
\series medium
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 in an analytic form.
 The common solution, is estimating quantiles by a resampling method.
 For resampling we use wild bootstrap 
\family default
\series default
\shape default
\size default
\emph on
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
method 
\emph default
proposed by
\emph on
 
\begin_inset CommandInset citation
LatexCommand cite
key "Shao2010,leucht_dependent_2013"

\end_inset

.
 
\emph default
We introduce an auxiliary wild bootstrap process 
\begin_inset Formula $\{W_{t,n}\}_{1\leq t\leq n}$
\end_inset

,
\end_layout

\begin_layout Standard

\emph on
\lang english
\begin_inset Formula 
\[
\ensuremath{W_{t,n}=\mathbf{1}(U_{t}>p_{n})W_{t-1,n}-\mathbf{1}(U_{t}<p_{n})W_{t-1,n},}
\]

\end_inset


\begin_inset Newline newline
\end_inset


\emph default
where 
\begin_inset Formula $W_{1,n}=1$
\end_inset

, 
\begin_inset Formula $U_{t}$
\end_inset

 is a series of iid uniform random variables 
\begin_inset Formula $p_{n}$
\end_inset

 is a probability of 
\begin_inset Formula $W_{t,n}$
\end_inset

 changing a sign.
 
\begin_inset Formula $W_{t,n}$
\end_inset

 is a Markov chain taking values in 
\begin_inset Formula $\{-1,1\}$
\end_inset

with symmetric probability a flip.
 In order to estimate empirical integral we will study a bootstrapped 
\begin_inset Formula $V$
\end_inset

-statistics
\end_layout

\begin_layout Standard

\emph on
\lang english
\begin_inset Formula 
\[
V_{b,n}(h,X)=\frac{1}{n}\sum_{i,j}W_{i,n}W_{j,n}h(X_{i,}X_{j})
\]

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X\sim p$
\end_inset

,
\begin_inset Formula $V_{b,n}(h,X)$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
 is a good approximation
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
of 
\begin_inset Formula $V_{n}(h)$
\end_inset

, which is simple application of the Theorem 3.1 
\begin_inset CommandInset citation
LatexCommand citep
key "leucht2012degenerate"

\end_inset

 
\end_layout

\begin_layout Theorem

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
of 
\begin_inset Formula $V_{n}$
\end_inset

.
 Let 
\begin_inset Formula $f(W_{t,n})=\sup_{x}|P(V_{b,n}>x|W_{t,n})-P(V_{n}>x)|$
\end_inset

 be a difference between quantiles.
 
\begin_inset Formula $f(W_{t,n})$
\end_inset

 converges to zero in probability.
 
\end_layout

\begin_layout Proof

\lang english
We have checked the assumption A2 in the proof of the Theorem 
\lang british

\begin_inset CommandInset ref
LatexCommand ref
reference "thm: null_dist"

\end_inset


\lang english
.
 The assumption B1 follows from our technical assumption 
\begin_inset Formula $\tau(t)\leq O(t^{-6})$
\end_inset

.
 Finally we check assumption B2 (bootstrap assumption):
\emph on
 
\begin_inset Formula $\{W_{t,n}\}_{1\leq t\leq n}$
\end_inset


\emph default
 is a row-wise strictly stationary triangular array independent of all 
\begin_inset Formula $Z_{t}$
\end_inset

 such that 
\begin_inset Formula $\ev W_{t,n}=0$
\end_inset

 and 
\begin_inset Formula $\sup_{n}\ev|W_{t,n}^{2+\sigma}|<\infty$
\end_inset

 for some 
\begin_inset Formula $\sigma>0$
\end_inset

.
 The auto-covariance of the process is given by 
\begin_inset Formula $\ev W_{s,n}W_{t,n}=(1-2p_{n})^{s-t}$
\end_inset

 , so the function 
\begin_inset Formula $\rho(x)=\exp(-x)$
\end_inset

, and 
\begin_inset Formula $l_{n}=\log(1-2p_{n})^{-1}$
\end_inset

.
 We verify that 
\begin_inset Formula $\lim_{u\to0}\rho(u)=1$
\end_inset

, 
\begin_inset Formula $l_{n}=o(n)$
\end_inset

 , 
\begin_inset Formula $\lim_{n\to\infty}l_{n}=\infty$
\end_inset

 and 
\begin_inset Formula $\sum_{r=1}^{n-1}\rho(|r|/l_{n})=O(l_{n})$
\end_inset

.
 
\end_layout

\begin_layout Standard
We now present the test procedure
\end_layout

\begin_layout Paragraph
The Test Procedure
\end_layout

\begin_layout Itemize
Calculate 
\lang english

\begin_inset Formula $V_{n}(h,X)$
\end_inset

.
\end_layout

\begin_layout Itemize

\lang english
Calculate
\lang british
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $\{V_{b,n}(h,X)\}_{\{i=1\}}^{D}$
\end_inset

 
\begin_inset Formula $D$
\end_inset

 times and estimate 
\begin_inset Formula $q_{1-\alpha}$
\end_inset

, the 
\begin_inset Formula $1-\alpha$
\end_inset

 empirical quantile of sequence 
\begin_inset Formula $\{V_{b,n}(h,X)\}_{\{i=1\}}^{D}$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
If 
\begin_inset Formula $V_{n}(h,X)>q$
\end_inset

, reject hypothesis that 
\begin_inset Formula $X\sim p$
\end_inset

.
\end_layout

\begin_layout Standard
One practical consideration is choice of flip parameter for the bootstrap
 process when dealing with non-iid data.
 While there is no good reprice for a finite sample and unknown covariance
 structure, in the first experiment we discuss a strategy applicable to
 chins obtained from MCMC methods.
\end_layout

\begin_layout Section

\lang english
Experiments
\end_layout

\begin_layout Standard

\lang english
Through all but one figure we present similar statistic -- distribution
 of p-values as a function of some parameter of interest.
 The general strategy for obtaining this distribution is the same throughout
 the experiences.
 We fix the parameter of interest, conduct one sample test some number of
 times (e.g.
 100 times) on 
\emph on
fresh data
\emph default
 
\end_layout

\begin_layout Subsection

\lang english
Student's t vs Normal
\end_layout

\begin_layout Standard

\lang english
In this sanity check we modify the experiment 4.1 from 
\begin_inset CommandInset citation
LatexCommand cite
key "gorham2015measuring"

\end_inset

.
 The null hypothesis is that observed samples 
\begin_inset Formula $x_{i}$
\end_inset

, for 
\begin_inset Formula $1\leq i\leq1300$
\end_inset

, come from a standard normal distribution.
 We verify power of the one-sample test by generating samples from Student's
 t distributions with increasing number of degrees of freedom -- powerful
 tests should low p-values for such samples .
 For the Student's t distribution with a number of degrees of freedom 
\begin_inset Formula $\nu$
\end_inset

, we draw 1400 samples and calculate the p-value -- this procedure is repeated
 100 times so 100 p-values are calculated and a bar plot of p-values is
 created.
 The bar plot for 
\begin_inset Formula $\nu=inf$
\end_inset

 is calculated for samples coming from normal distribution.
\end_layout

\begin_layout Standard
The twist to 
\lang english
experiment 4.1 from 
\begin_inset CommandInset citation
LatexCommand cite
key "gorham2015measuring"

\end_inset

 is that our samples have temporal dependency.
 The observations are generated using Metropolisâ€“Hastings algorithm, with
 Gaussian random walk (variance equal to 0.5).
 We emphasize the need for appropriate choice of bootstrap process, namely
 the probability of a sign flip.
 In the figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:studentst"

\end_inset

 we plot p-values for the probability of flip 
\begin_inset Formula $p_{n}=2\%$
\end_inset

, while in the 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:student_bad"

\end_inset

 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p_{n}=50\%$
\end_inset

.
 
\begin_inset Formula $p_{n}=50\%$
\end_inset

, which would be suitable for iid observations, is way too conservative
 for temporally dependent observations.
 The solution we recommend is a mixture of thinning and adjusting 
\begin_inset Formula $p_{n},$
\end_inset

 as presented in the last figure, where we have used thinned observations
 by 20 and set 
\begin_inset Formula $p_{n}=10\%$
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "fig:studentst"

\end_inset


\begin_inset Graphics
	filename img/sgld_student.pdf

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Large auto covariance, and suitable bootstrap.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "fig:student_bad"

\end_inset


\begin_inset Graphics
	filename img/sgld_student_bad.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Large auto covariance, and bootstrap that ignores auto covariance structure.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:thinning"

\end_inset


\begin_inset Graphics
	filename img/sgld_student_opt.pdf

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Thinned sample, and suitable bootstrap.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\lang english
MCMC diagnostic
\end_layout

\begin_layout Standard

\lang english
This one sample test can be used for diagnostics of most of the MCMC methods.
 In the following experiment we will demonstrate how to verify if the samples
 obtained form two sampling can be assumed to come from the stationary distribut
ion.
\end_layout

\begin_layout Standard

\lang english
Here we multi modal ilustrative model used before in 
\begin_inset CommandInset citation
LatexCommand citet
key "gorham2015measuring,welling2011bayesian"

\end_inset

.
 The model is 
\begin_inset Formula 
\begin{align*}
\theta_{1}\sim N(0,10);\theta_{2}\sim N(0,1)\\
X_{i}\sim\frac{1}{2}N(\theta_{1},4)+\frac{1}{2}N(\theta_{2},4)
\end{align*}

\end_inset

400 points are drawn from this model.
 The task is to estimate a posteriori distribution of 
\begin_inset Formula $\theta$
\end_inset

.
 
\end_layout

\begin_layout Paragraph

\lang english
Metropolis Hastings with random walk
\end_layout

\begin_layout Standard

\lang english
We use plain MH MCMC with Gaussian proposal with with standard deviation
 equal to 
\begin_inset Formula $0.2$
\end_inset

.
\end_layout

\begin_layout Subsection

\lang english
Approximate MCMC algorithm 
\end_layout

\begin_layout Standard

\lang english
Austerity MCMC 
\begin_inset CommandInset citation
LatexCommand citet
key "korattikara2013austerity"

\end_inset

is a Monte Carlo procedure designed to reduce number of likelihood evaluation
 in the acceptance step of the Metropolis-Hastings algorithm.
 The crux of algorithm is to look just at a subset of the data and make
 a acceptance/rejection decision based on this subset.
 The probability of which making a wrong decision is proportional to 
\begin_inset Formula $\epsilon\in[0,1]$
\end_inset

.
 Not surprisingly parameter 
\begin_inset Formula $\epsilon$
\end_inset

 influences time complexity of Austerity MCMC, the larger 
\begin_inset Formula $\epsilon$
\end_inset

, hence toleration for a mistake, the lower computational cost, on average.
 We simulate 
\begin_inset Formula $\{X_{i}\}_{\{1\leq i\leq400\}}$
\end_inset

 points from the model with 
\begin_inset Formula $\theta_{1}=0$
\end_inset

 and 
\begin_inset Formula $\theta_{2}=1$
\end_inset

.
 In such a setting there are two modes in the posteriori distribution, one
 at the the point 
\begin_inset Formula $0,1$
\end_inset

 and the other at the point 
\begin_inset Formula $1,-1$
\end_inset

.
 We run the Austerity algorithm with 
\begin_inset Formula $\epsilon$
\end_inset

 varying in a range 
\begin_inset Formula $[0.001,0.2]$
\end_inset

.
 For each 
\begin_inset Formula $\epsilon$
\end_inset

 we calculate individual thinning factor such that correlation between consecuti
ve elements of samples form the chains is smaller than 
\begin_inset Formula $0.5$
\end_inset

 (greater 
\begin_inset Formula $\epsilon$
\end_inset

 require usually more less thinning).
 For each 
\begin_inset Formula $\epsilon$
\end_inset

 we then sample 
\begin_inset Formula $\{\theta_{i}\}_{1\leq i\leq500}$
\end_inset

 and calculate a p-value using present one sample test.
 This way we generate 100 p-values for each 
\begin_inset Formula $\epsilon$
\end_inset

 ,the Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "p-values"

\end_inset

shows distribution of those p-values as a function of 
\begin_inset Formula $\epsilon$
\end_inset

 -- 
\begin_inset Formula $\epsilon=0.04$
\end_inset

 gives a good approximation of true stationary distribution.
 We also collect statistics about average number of likelihood evaluations,
 these are presented in the figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "lik-evals"

\end_inset

 (y-axis is in millions of evaluations).
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\lang english
\begin_inset CommandInset label
LatexCommand label
name "p-values"

\end_inset


\begin_inset Graphics
	filename img/Heiko1.pdf

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "lik-evals"

\end_inset

 
\begin_inset Graphics
	filename img/Heiko2.pdf

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Convergence in non-parametric density estimation
\end_layout

\begin_layout Standard
Our next experiment illustrates using the developed test to asses estimation
 quality in the context of nonparametricdensity estimation.
 We quantify estimation quality and approximation quality of the infinite
 dimensional exponential family model 
\begin_inset CommandInset citation
LatexCommand citep
key "SriFukKumGreHyv14"

\end_inset

 and its recent random Fourier features approximation 
\begin_inset CommandInset citation
LatexCommand citep
key "strathmann2015gradient"

\end_inset

 respectively.
\end_layout

\begin_layout Standard
The original model's (un-normalised) log pdf is given by 
\begin_inset Formula $f(x)$
\end_inset

 where 
\begin_inset Formula $f\in{\cal H}$
\end_inset

 lies in a Reproducing Kernel Hilbert Space 
\begin_inset Formula ${\cal H}$
\end_inset

 induced by a Gaussian kernel with bandwidth 1.
 We fit the model to 
\begin_inset Formula $N$
\end_inset

 standard Gaussian distributed data and perform our quadratic time test
 on seperate test data of a fixed size 
\begin_inset Formula $N_{\text{test}}=500$
\end_inset

.
 We aim to identify the number of samples necessary to make model and data
 indistinguishable for a test of a certain power.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:density_estimation_increasing_data"

\end_inset

 shows the distribution of p-values for this particualar test power 
\begin_inset Formula $N_{\text{test}}$
\end_inset

 is uniform for 
\begin_inset Formula $N=5000$
\end_inset

, but already at 
\begin_inset Formula $N=500$
\end_inset

, the null hypothesis would very rarely be rejected.
\end_layout

\begin_layout Standard
We now use the recent random Features approximation 
\begin_inset CommandInset citation
LatexCommand citep
key "strathmann2015gradient"

\end_inset

 where the log pdf is taken to be 
\begin_inset Formula $\theta^{\top}\phi_{x}$
\end_inset

 where 
\begin_inset Formula $\theta\in\mathbb{R}^{m}$
\end_inset

 and 
\begin_inset Formula $\phi_{x}\in\mathbb{R}^{m}$
\end_inset

 is the random Fourier feature embedding 
\begin_inset CommandInset citation
LatexCommand citep
key "Rahimi2007"

\end_inset

.
 The natural question when using this approximation is: 
\begin_inset Quotes eld
\end_inset

How many random features do it I need?
\begin_inset Quotes erd
\end_inset

 Using the same test power 
\begin_inset Formula $N_{\text{test}}=500$
\end_inset

 as above, and a large number of available samples 
\begin_inset Formula $N=5\cdot10^{4}$
\end_inset

, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:density_estimation_increasing_features"

\end_inset

 shows the distribution of p-values for an increasing number of random features
 
\begin_inset Formula $m$
\end_inset

.
 From about 
\begin_inset Formula $m=50$
\end_inset

, the null hypothesis would rarely be rejected for the chosen test power.
\end_layout

\begin_layout Standard
and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:density_estimation_increasing_features"

\end_inset

 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/increasing_data_fixed_test.eps

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
P-values for an increasing number of data 
\begin_inset Formula $N$
\end_inset

 for the non-parametric model.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:density_estimation_increasing_data"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/increasing_features_fixed_test.eps

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
P-values for an increasing number of random features 
\begin_inset Formula $m$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:density_estimation_increasing_features"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
git 
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "biblio"
options "icml2015"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
normalsize
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
onecolumn
\end_layout

\end_inset


\end_layout

\begin_layout Part*
Appendix
\end_layout

\begin_layout Section

\lang english
boring proofs
\end_layout

\begin_layout Proof
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:BochnerInt"

\end_inset


\lang english
It is sufficient to check that coefficients of 
\begin_inset Formula $\xi$
\end_inset

 are Bochner integrable (
\begin_inset CommandInset citation
LatexCommand cite
after "Definition A.5.20"
key "SteChr08"

\end_inset

).
 first we check that for random any variable 
\begin_inset Formula $Z$
\end_inset

 
\begin_inset Formula 
\[
\ev\left\Vert \frac{\partial\log p(Z)}{\partial x_{i}}k(Z,\cdot)\right\Vert ^{2}=\ev\left(\frac{\partial\log p(Z)}{\partial x_{i}}k(Z,Z)\right)^{2}<\ev\|\nabla\log p(X)\|^{2}<\infty,
\]

\end_inset

which follows form assumption (i) and boundedness of the kernel.
 Next we check that 
\begin_inset Formula 
\[
\ev\left\Vert \frac{\partial k(Z,\cdot)}{\partial x}\right\Vert ^{2}=\ev\left(\frac{\partial^{2}k(Z,Z)}{dx_{i}dx_{i+d}}\right)^{2}<\infty,
\]

\end_inset

which follows from assumption (iii).
 
\end_layout

\begin_layout Proof

\lang english
\begin_inset CommandInset ref
LatexCommand ref
reference "th1"

\end_inset

Recall that use notation 
\begin_inset Formula 
\begin{align*}
\nabla_{1}k(x,y)=\left(\frac{\partial k(x,y)}{\partial x_{1}},\cdots,\frac{\partial k(x,y)}{\partial x_{d}}\right)\\
\nabla_{2}k(x,y)=\left(\frac{\partial k(x,y)}{\partial y_{1}},\cdots,\frac{\partial k(x,y)}{\partial y_{d}}\right).\\
\end{align*}

\end_inset

and 
\begin_inset Formula $\langle\cdot,\cdot\rangle_{2}$
\end_inset

 for inner product in 
\begin_inset Formula $R^{d}$
\end_inset

.
 
\begin_inset Formula 
\begin{align*}
S(X,\mathcal{F},p)^{2} & =\langle\xi,\xi\rangle_{\mathcal{F}^{d}}\\
 & =\langle\ev\left[\nabla\log p(X)k(X,\cdot)+\nabla_{1}k(X,\cdot)\right],\ev\left[\nabla\log p(X)k(X,\cdot)+\nabla_{1}k(X,\cdot)\right]\rangle_{\mathcal{F}^{d}}\\
 & =\ev\langle\nabla\log p(X_{1})k(X_{1},\cdot)+\nabla_{1}k(X_{1},\cdot),\nabla\log p(X_{2})k(\cdot,X_{2})+\nabla_{2}k(\cdot,X_{2})\rangle_{\mathcal{F}^{d}}\\
 & =\ev\langle\nabla\log p(X_{1}),\nabla\log p(X_{2})\rangle_{2}k(X_{1},X_{2})+\ev\langle\nabla p(X_{2}),\nabla_{1}k(X_{1},X_{2})\rangle_{2}\\
 & \quad+\ev\langle\nabla\log p(X_{1}),\nabla_{2}k(X_{1},X_{2})\rangle_{2}+\ev\ \langle\nabla_{1}k(X_{1},X_{2}),\nabla_{2}k(X_{1},X_{2})\rangle_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof

\lang english
\begin_inset CommandInset ref
LatexCommand ref
reference "thm: null_dist"

\end_inset

The condition A1 is trivially stratified by the assumption 
\begin_inset Formula $\sum_{t=1}^{\infty}\sqrt{\tau(t)}\leq\infty$
\end_inset

.
 The condition A2 (iv), Lipschitz continuity.
 follows form the assumption iv).
 The positive definiteness and degeneracy follows form the proof of th the
 Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th2"

\end_inset

.
 Indeed
\end_layout

\begin_layout Proof

\lang english
\begin_inset Formula 
\[
h(x,y)=\langle\left[\nabla\log p(x)k(x,\cdot)+\nabla_{1}k(x,\cdot)\right],\left[\nabla\log p(y)k(y,\cdot)+\nabla_{1}k(y,\cdot)\right]\rangle_{\mathcal{F}^{d}}
\]

\end_inset


\begin_inset Newline newline
\end_inset

so it's an inner product and hence positive definite.
 Degeneracy follows form the fact that for ant 
\begin_inset Formula $t$
\end_inset

, by Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:easy"

\end_inset

,
\begin_inset Formula $\ev\nabla\log p(x)k(x,t)+\nabla_{1}k(x,t)=0$
\end_inset

.
 Finally the condition A2 (iii), 
\begin_inset Formula $\ev h(X,X)\leq\infty$
\end_inset

 follows form (ii), (iii) and boundlessness of the kernel.
\end_layout

\begin_layout Lemma

\lang english
\begin_inset CommandInset label
LatexCommand label
name "lem:easy"

\end_inset

 If a random variable 
\begin_inset Formula $X$
\end_inset

 is distributed according to 
\begin_inset Formula $p$
\end_inset

, then for all function 
\begin_inset Formula $f\in\mathcal{F}$
\end_inset

 expected value of 
\begin_inset Formula $T_{p}$
\end_inset

 is zero, i.e.
 
\begin_inset Formula $\forall_{f\in\mathcal{F}}\ev(T_{q}f)(X)=0$
\end_inset

.
\end_layout

\begin_layout Proof

\lang english
First we show that the functions 
\begin_inset Formula $g_{i}=p\cdot f_{i}$
\end_inset

 vanish at infinity, by which we mean that for all dimensions 
\begin_inset Formula $j$
\end_inset

 
\begin_inset Formula 
\[
\lim_{x_{j}\to\infty}g_{i}(x_{1},\cdots,x_{d})=0.
\]

\end_inset

The density function 
\begin_inset Formula $p$
\end_inset

 vanishes at infinity.
 The function 
\begin_inset Formula $f$
\end_inset

 is bounded, which is implied by Cauchy-Schwarz inequality -- 
\begin_inset Formula $\left|f(x)\right|\le\left\Vert f\right\Vert \sqrt{k(x,x)}$
\end_inset

.
 This implies that the function 
\begin_inset Formula $g$
\end_inset

 vanishes at infinity.
 To show the expected value 
\begin_inset Formula $\ev(T_{p})f(X)$
\end_inset

 is zero, it is sufficient to show that for all dimensions 
\begin_inset Formula $i$
\end_inset

, the expected value of 
\begin_inset Formula $\frac{\partial\log p(X)}{\partial x_{i}}f_{i}(X)+\frac{\partial f_{i}(X)}{\partial x_{i}}$
\end_inset

 is zero.
 
\begin_inset Formula 
\begin{align*}
 & \ev\left(\frac{\partial\log p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}\right)\\
 & =\int_{R_{d}}\left[\frac{\partial\log p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}\right]q(x)dx\\
 & =\int_{R_{d}}\left[\frac{1}{p(x)}\frac{\partial q(x)}{\partial x_{i}}f(x)+\frac{\partial f(x)}{\partial x_{i}}\right]q(x)dx\\
 & =\int_{R_{d}}\left[\frac{\partial p(x)}{\partial x_{i}}f_{i}(x)+\frac{\partial f_{i}(x)}{\partial x_{i}}q(x)\right]dx\\
 & \overset{(a)}{=}\int_{R_{d-1}}\left(\lim_{R\to\infty}p(x)f_{i}(x)\bigg|_{x_{i}=-R}^{x_{i}=R}\right)dx_{1}\cdots dx_{i-1}\cdots dx_{i+1}\cdots d{x_{d}}\\
 & =\int_{R_{d-1}}0dx_{1}\cdots dx_{i-1}\cdots dx_{i+1}\cdots d{x_{d}}\\
 & =0.
\end{align*}

\end_inset

For the equation (a) we have used integration by parts and fact that 
\begin_inset Formula $g_{i}$
\end_inset

 vanishes at infinity.
 
\end_layout

\begin_layout Subsection

\lang english
Linear time
\end_layout

\begin_layout Standard

\lang english
For some fixed location 
\begin_inset Formula $y$
\end_inset

 and a random variable 
\begin_inset Formula $X$
\end_inset

, define a random variable 
\begin_inset Formula $s(X,y)$
\end_inset

 
\begin_inset Formula 
\begin{align}
s(X,y)=\nabla\log p(X)g(X,y)-\nabla g(X,y).
\end{align}

\end_inset

For some number of random locations 
\begin_inset Formula $Y_{1},Y_{J}$
\end_inset

 and a random variable 
\begin_inset Formula $X$
\end_inset

 define a random vector 
\begin_inset Formula $Z_{i}$
\end_inset

 
\begin_inset Formula 
\begin{equation}
Z_{i}=(s(X_{i},Y_{1}),\cdots,s(X_{i},Y_{J}))\in\mathbf{R}^{J}.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
Let 
\begin_inset Formula $W_{n}$
\end_inset

 be a mean of 
\begin_inset Formula $Z_{i}$
\end_inset

's 
\begin_inset Formula $W_{n}=\frac{1}{n}\sum_{i=1}^{n}Z_{i},$
\end_inset

 and 
\begin_inset Formula $\Sigma_{n}$
\end_inset

 its covariance matrix 
\begin_inset Formula $\Sigma_{n}=\frac{1}{n}ZZ^{T}$
\end_inset

.
 The test statistic is 
\begin_inset Formula 
\begin{equation}
S_{n}=nW_{n}\Sigma_{n}^{-1}W_{n}.
\end{equation}

\end_inset

The computation of 
\begin_inset Formula $S_{n}$
\end_inset

 requires inversion of a 
\begin_inset Formula $J\times J$
\end_inset

 matrix 
\begin_inset Formula $\Sigma_{n}$
\end_inset

, but this is fast and numerically stable: 
\begin_inset Formula $J$
\end_inset

 will typically be small, and is less than 10 in our experiments.
 The next proposition demonstrates the use of 
\begin_inset Formula $S_{n}$
\end_inset

 as a one-sample test.
\end_layout

\begin_layout Proposition

\lang english
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\lang english
Asymptotic behavior of 
\begin_inset Formula $S_{n}$
\end_inset


\end_layout

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "prop:Hotelling"

\end_inset

 If 
\begin_inset Formula $\ev s(X,y)=0$
\end_inset

 for all 
\begin_inset Formula $y$
\end_inset

, then the statistic 
\begin_inset Formula $S_{n}$
\end_inset

 is a.s.
 asymptotically distributed as a 
\begin_inset Formula $\chi^{2}$
\end_inset

-random variable with 
\begin_inset Formula $Jd$
\end_inset

 degrees of freedom, where 
\begin_inset Formula $d$
\end_inset

 is 
\begin_inset Formula $X$
\end_inset

 dimensionality (as 
\begin_inset Formula $n\to\infty$
\end_inset

 with 
\begin_inset Formula $d$
\end_inset

 fixed).
 If 
\begin_inset Formula $\ev s(X,y)\neq0$
\end_inset

 for almost all 
\begin_inset Formula $y$
\end_inset

 then a.s.
 for any fixed 
\begin_inset Formula $r$
\end_inset

, 
\begin_inset Formula $\mathbb{P}(S_{n}>r)\to1$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

 .
 
\end_layout

\begin_layout Paragraph

\lang english
One sample test
\end_layout

\begin_layout Standard

\lang english
Calculate 
\begin_inset Formula $S_{n}$
\end_inset

.
 Choose a threshold 
\begin_inset Formula $r_{\alpha}$
\end_inset

 corresponding to the 
\begin_inset Formula $1-\alpha$
\end_inset

 quantile of a 
\begin_inset Formula $\chi^{2}$
\end_inset

 distribution with 
\begin_inset Formula $J$
\end_inset

 degrees of freedom, and reject the null hypothesis whenever 
\begin_inset Formula $S_{n}$
\end_inset

 is larger than 
\begin_inset Formula $r_{\alpha}$
\end_inset

.
 
\end_layout

\end_body
\end_document
